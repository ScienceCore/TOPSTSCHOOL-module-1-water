---
title: "WSIM-GLDAS Dataset Exploration and Visualizations"
author: 
  - "Joshua Brinks"
  - "Elaine Famutimi"
date: "December, 6 2023"
bibliography: wsim-gldas-references.bib
---

## Overview

In our previous lesson, _Acquiring and Pre-Processing the WSIM-GLDAS Dataset_, we downloaded components of WSIM-GLDAS from SEDAC, subsetted the data using vector boundaries from geoBoundaries, performed a visual check, and wrote the file to disk. In this lesson, we will extend our work with WSIM-GLDAS by introducing an additional integration period, calculating simple summary statistics, integrating WSIM-GLDAS with the Gridded Population of the World, and developing more complex visualizations.

## Learning Objectives

After completing this lesson, you should be able to:

-   Subset data for a region and time period of interest.
-   Summarize raster data with zonal extractions.
-   Perform visual exploration with histograms and time series figures.
-   Use different plotting functions to make these maps.
-   Integrate multiple spatial datasets to perform more complex analyses.

## Introduction

::: column-margin
::: {.callout-tip style="color: #5a7a2b;"}

## Coding Review

This lesson uses the [`stars`](), [`lubridate`](), [`exactextractr`](), [`ggplot`](https://ggplot2.tidyverse.org/), and [`terra`](https://rspatial.org/pkg/) packages. If you'd like to learn more about the functions used in this lesson you can use the help guides on their package websites.
:::
:::

## Load Data

We'll being with the WSIM-GLDAS 12 month integration anomaly file from SEDAC and quickly subset it to the Continental United States (CONUSA). We can reduce our memory overhead by reading in just the `'deficit'` attribute from the WSIM-GLDAS composite 12 month integration file.

```{r warning=FALSE}
#| code-fold: true
wsim_gldas <- stars::read_stars("composite_12mo.nc", proxy = FALSE, sub = 'deficit')

print(wsim_gldas)
```

For this exercise we want to explore droughts in the continental United States for the years 2000-2014. In the 12 momth integration dataset, each monthly time step is an average of the previous 12 months. Therefore, if we wish to view a snapshot of drought for a given year we need to use the December timestep for that year. We can create a sequence of dates starting with December 2000 to get every year until 2014.

```{r warning=FALSE}
# generate a vector of dates for subsetting
keeps<-seq(lubridate::ymd("2000-12-01"),
           lubridate::ymd("2014-12-01"), 
           by = "year")

# filter using that vector
wsim_gldas <- dplyr::filter(wsim_gldas, time %in% keeps)
print(wsim_gldas)

```

Now can subset the WSIM-GLDAS dataset using the USA country boundary from geoBoundaries.

```{r warning=FALSE}
#directly acquire the boundary from geoBoundaries API
usa <- httr::GET("https://www.geoboundaries.org/api/current/gbOpen/USA/ADM1/")
usa <- httr::content(usa)
usa <- sf::st_read(usa$gjDownloadURL)

# remove everything not part of CONUSA
drops<-
  c("Alaska", "Hawaii", 
    "American Samoa",
    "Puerto Rico",
    "Commonwealth of the Northern Mariana Islands", 
    "Guam", 
    "United States Virgin Islands")

usa<-usa[!(usa$shapeName %in% drops),]
wsim_gldas<-wsim_gldas[usa]
```

Now we'll verify the pre-processing steps with `print()`. The raster object now contains 15 timesteps from 

```{r}
print(wsim_gldas)
```

## Multi-Panel Time Series

We can start our visual exploration of annual drought in the CONUSA with a time series plot depicting each year in the dataset.

```{r warning = TRUE}
# the histogram can be studied to properly choose breaks. Breaks chosen are [-60, -40, -20, 0, 20, 40, 50] from studying the histogram.

wsim_gldas |>
  plot(reset = FALSE,
       col = leg_colors<-c(
    '#9B0039',
    # -50 to -40
    '#D44135',
    # -40 to -20
    '#FF8D43',
    # -20 to -10
    '#FFC754',
    # -10 to -5
    '#FFEDA3',
    # -5 to -3
    '#FFF4C7'), breaks = c(-60, -50, -40, -20, -10,-5, 0))
```

There are several significant drought events throughout 2000-2014. The southeast in 2000, southwest in 2002, the majority of the western 3rd in 2007, Texas-Oklahoma in 2011, Montana-Wyoming-Colorado in 2012, and the entirety of the California coast in 2014. The droughts of 2012 and 2011 are particularly severe and widespread with return periods greater than 50 covering multiple states. Based on historical norms, we should only expect droughts this strong every 50-60 years!

We can get a better look at these drought events by using the 1 month composite WSIM-GLDAS dataset and subsetting the data with a smaller spatial extent. Let's examine the 2014 California drought.

To reduce our memory overhead, we'll start by removing the 12 month composite object.

```{r}
rm(wsim_gldas)
```

Now let's load the composite 1 month file from SEDAC.

```{r}
gc()
wsim_gldas_1mo <- stars::read_stars("composite_1mo.nc", sub = 'deficit', proxy = FALSE)

print(wsim_gldas_1mo)
```

Once again, we'll subset the time dimension for our period of interest. This time we want every month for 2014.

```{r}
# generate a vector of dates for subsetting
keeps<-seq(lubridate::ymd("2014-01-01"),
           lubridate::ymd("2014-12-01"), 
           by = "month")

# filter using that vector
wsim_gldas_1mo <- dplyr::filter(wsim_gldas_1mo, time %in% keeps)
print(wsim_gldas_1mo)
```


```{r}
# subset for USA
wsim_gldas_1mo<-wsim_gldas_1mo[usa]

# subset for deficit
wsim_gldas_1mo_usa <- wsim_gldas_1mo['deficit']
print(wsim_gldas_1mo)
```



```{r}
# create a new sequence of dates, this time monthly, for the chosen year of 2011
keeps3<-seq(lubridate::ymd("2012-01-01"),
           lubridate::ymd("2012-12-01"), 
           by = "month")

#change data type to POSIXct
#keeps3 <- as.POSIXct(keeps3)

wsim_gldas_1mo <- dplyr::filter(wsim_gldas_1mo, time %in% keeps3)
print(wsim_gldas_1mo)
```
The output shows that we've selected a single attribute ('deficit') and 15 time-steps in the 'time' dimension. We'll plot the last timestep to check the visuals on our raster data.

```{r warning=FALSE, message=FALSE}
wsim_gldas |>
  dplyr::slice(index = 15, along = "time") |>
  plot(reset = FALSE, breaks = rev(c(0,-5,-10,-20,-40,-50, -75)))

plot(sf::st_geometry(usa),
     add = TRUE,
     lwd = 3,
     fill = NA,
     border = 'purple')
```
This looks reasonable. There are widespread water deficits all throughout the western USA.

## Exploratory Histogram

We can get a different view of the data by creating a histogram of the deficit anomalies. This allows

```{r}
# filter for the first time-step in the file
deficit_hist <-  
  wsim_gldas |>
  dplyr::slice(time, 15) |>
  as.data.frame(wsim_gldas$deficit)
```

Check the values.

```{r}
ggplot2::ggplot(deficit_hist, ggplot2::aes(deficit))+
  ggplot2::geom_histogram(na.rm = TRUE)+
  ggplot2::xlim(c(0,-70))
```

Although most of the country has a deficit anomaly of less than 10 years, more than 5 thousand cells have return periods of 60 years or more! Most of these are along the California coast.

```{r}
ggplot2::ggplot(usa1, ggplot2::aes(Deficit))+
  ggplot2::geom_histogram(na.rm = TRUE)+
  ggplot2::xlim(c(-60,50))
```



Create a multi-panel figure with each panel representing 1 month to identify the most intense months of drought or flooding. Starting with this one maybe use `ggplot` and a nice palette, legend, and panel headings. Will probably have to use some sort of faceting to make individual panels.


```{r}
# turn into dataframe
df_wsim_gldas_1mo <-as.data.frame(wsim_gldas_1mo, xy = TRUE) 

ggplot2::ggplot(data = df_wsim_gldas_1mo) +
  ggplot2::geom_raster(ggplot2::aes(x = x, y = y, fill = deficit)) +
  ggplot2::scale_fill_viridis_c(limits = c(-60, 60), option = "magma") +
  ggplot2::theme_void() +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::geom_sf(data = usa, fill = NA, color = "black") +
  ggplot2::facet_wrap(time ~ .)

```

Visualize an individual cell with particular extreme or maybe volatile values. Use Google Maps to identify the latitude/longitude of a place of interest. Maybe an urban center or other important location in the region that suffered from the extreme event.

Create a vector with the point location.

```{r}
# vector of coordinates Missouri River Basin
coords <- c(-95.833471, 40.721001)

# create a stars object with point coordinates where 'sf::st_sfc()' is used to create a geometry list column and add a coordinate reference system. 'sf::st_points()' is within that function to turn the coords vector into a point. 'sf:: st_crs()' and 'stars::st_dimensions()'  respectively retrieves the coordinate reference system and the dimensions of wsim_gldas_1mo to ensure that the final values in point_stars is the same reference system and shape. 

point_stars <- sf::st_sfc(sf::st_point(coords), crs = sf::st_crs(wsim_gldas_1mo),
                      dim = names(stars::st_dimensions(wsim_gldas_1mo)))
```

Use `stars::extract` to extract raster values in the stack at the point location.

```{r}
extracted_vals <- stars::st_extract(wsim_gldas_1mo, point_stars)
```

The resulting data frame of time series values should be inspected. It may also need to be converted from wide format to long format so it may be plotted in `ggplot`. Use either pivot wider/longer from `dplyr` or cast/melt from `data.table`.

```{r}
# convert to dataframe
extracted_df <- as.data.frame(extracted_vals)

print(extracted_df)
```

Once in the proper format, plot using `ggplot`.

```{r}
ggplot2::ggplot(extracted_df, ggplot2::aes(x = time, y = deficit)) + ggplot2::geom_line()
```

\*\*Creating a time series similar to this can be useful in water resources management, which is the process of planning and managing water resources across all water uses. One can use time series analysis in models to predict droughts and flooding. It helps water resource managers determine who is able to use the available water.

However, sometimes there can be issues in water resources management, especially across separate divisions. In 2012, Missouri experienced a severe drought that was the worst in more than 50 years, which negatively impacted the Missouri River Basin. A river basin is described as a total area of land that is drained by a river and it's tributaries, while tributaries are rivers or streams that flow into a larger river.

The Army Corps of Engineers reduced the flow from Gavins Point Dam, a Missouri River reservoir, to protect the upper Missouri River basin in November 2012. That caused tension between water demand in the basin and transport demand on the Mississippi River, since the Missouri River flows into the Mississippi River. Additionally, Mississippi was also experiencing a drought.[@USAToday2012]

The Missouri River Basin functions for drinking water, irrigation and industrial purposes, and power production, while the Mississippi River benefits industries that rely on the river for trade and transport, which is important for the region's economy. Since both rivers are managed by difference offices, it was hard to determine a water resources solution that wouldn't impact both rivers.[@WorldView2012]

## Population Exposure Plot

Use Gridded Population of the World and `exactextractr` to determine the number of people exposed to a given anomaly for each month of the year [@Baston2023].

**Gridded Population of the World** is a dataset group in SEDAC which models the distribution of the global human population through counts and densities on a raster. It displays the global distribution of the human population on a continuous surface. There are other versions of Gridded Population of the World, and the one used in this tutorial is the fourth version. Past versions like the third one, has been used for disaster impacts and environmental change.

This version has been updated using 2010 census data and is built from the previous versions. The accuracy of Gridded Population of the World version 4 was improved due to improvements in technology that allowed the Census bureaus to effortlessly distribute their results to the public using electronic and online formats.

These estimates are available for the years of 2000, 2005, 2015 and 2020. The Population Count dataset will be used for this example, and can be downloaded from the NASA [SEDAC](https://sedac.ciesin.columbia.edu/data/collection/gpw-v4) website [@CIESIN2018]. For this upcoming example, you will need to download the .tif file for the year of 2020, at the 15 minute resolution.

[exactextractr](https://github.com/isciences/exactextractr) [@Baston2023] is an R package that summarizes raster values over groupings, or zones, also known as zonal statistics. Zonal statistics help in assessing the statistical characteristics of a certain region. The package can be used to sum all the cells in a polygon, i.e. a region; other functions include computing the mean, median, and other types of statistics.

Load in GPW data using `terra` and the `exactextractr` package

```{r}
library(exactextractr)

gpw1 <- terra::rast("gpw_v4_population_count_rev11_2020_15_min.tif")
print(gpw1)
```

Perform the time series zonal summary.

This might be a bit tricky; been a while for me. Have to look up the proper code. Dan has good examples on the exactextractr package website.

Resulting data.frame will probably need to be transformed to long (just like before), so it can be plotted.

```{r}
extracted_mean <- exact_extract(gpw1, usa, 'mean')
print(extracted_mean)

extracted_mean_df <- as.data.frame(extracted_mean)
print(extracted_mean_df)
```

You will have to use the function "cbind" to bind together the extracted mean of each state along with the states in the USA boundary.

```{r}
joined_var = cbind(usa, extracted_mean)
print(joined_var)

joined_var_df = as.data.frame(joined_var)
print(joined_var_df)
```

Now plot the data in ggplot. Add a title and label the axis. I have some existing code I can pull to help with the plotting--or at least make it fancy.

```{r}
ggplot2::ggplot(data = joined_var_df, ggplot2::aes(x = shapeName, y = extracted_mean, group = 1)) + ggplot2::geom_line() +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90, hjust = 1)) +
  ggplot2::theme(plot.title =  ggplot2::element_text(hjust = 0.5)) +
  ggplot2::ggtitle("Population Mean per State") + 
  ggplot2::xlab("State") + 
  ggplot2::ylab("Mean")
```

## In this Lesson, You Learned...

Congratulations! Now you should be able to:

-   Download geoboundaries data using the httr::GET() method.

-   Identify hot spots of precipitation data and select these hotspots for further analysis by subsetting.

-   Extract data from a pixel by using the extract function from the Stars library.

-   Perform zonal statistics of population data using the extractexactr library.

## Conclusion

The insights drawn from various data sources, including remote sensing data, contribute to the understanding of water availability. Models like the Global Land Data Assimilation System (GLDAS) utilize satellite and ground-based observations to provide real-time, high-resolution data on land surface states and fluxes, aiding in a more comprehensive understanding of drought and flooding [@Rodell2004].
