[
  {
    "objectID": "wsim-gldas-acquisition.html",
    "href": "wsim-gldas-acquisition.html",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "",
    "text": "Add context for package selection\n\nstars for raster management\nsf for vector/shapefile/geojson\nlubridate for date management\n\nMore dataset context/explanation (geoBoundaries vs gadm).\nCitations and external links for data and packages.\nDecide on which wsim-gldas version to use.\n\nSwitch out the current for a 12-month integration anomaly.\n\nWrite out the smaller pre-processed file to disk for potential use in binder workshop or subsequent lesson in the module.\nIntroduce automated data acquisition with some sedac or earthdata package??"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#to-do",
    "href": "wsim-gldas-acquisition.html#to-do",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "",
    "text": "Add context for package selection\n\nstars for raster management\nsf for vector/shapefile/geojson\nlubridate for date management\n\nMore dataset context/explanation (geoBoundaries vs gadm).\nCitations and external links for data and packages.\nDecide on which wsim-gldas version to use.\n\nSwitch out the current for a 12-month integration anomaly.\n\nWrite out the smaller pre-processed file to disk for potential use in binder workshop or subsequent lesson in the module.\nIntroduce automated data acquisition with some sedac or earthdata package??"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#introduction",
    "href": "wsim-gldas-acquisition.html#introduction",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Introduction",
    "text": "Introduction\nThe Water Security (WSIM-GLDAS) Monthly Grids, v1 (1948 – 2014) dataset can be download from the NASA SEDAC website (ISciences and Center For International Earth Science Information Network-CIESIN-Columbia University 2022). Downloads are organized by combination of variable (composite surplus/deficit, temperature, PETmE, runoff, soil moisture, precipitation) and integration period (1, 3, 6, 12 months). Each variable-integration combination consists of a NetCDF raster file with a time dimension that contains a raster layer for each of the 804 months between January, 1948 and December, 2014. Some variables also contain multiple attributes each with their own time dimension of 804 rasters. Hence, this is a large file that takes upwards of 2 hours to download and may cause memory issues on certain systems. We will work with the composite anomolies integrated over 1 month periods.\nA raster is a grid of geographic data which has information stored per pixel. Vectors are a collection or a list of numbers. Vectors can be used to store coordinates, which can then be used to extract information from a pixel in the raster for analysis, such as a time series. Rasters can store many types of information as attributes, and they usually have dimensions such as latitude, longitude, and time.\nThe water cycle is the constant process of circulation of water on, above, and under the Earth’s surface. Human interventions such as greenhouse gas emissions, land use changes, dam and reservoir development, and groundwater overexploitation have all drastically affected the natural water cycle in recent decades. Human interventions in the water cycle have consequential impacts on oceanic, groundwater, and land processes, influencing phenomena such as droughts and floods.\nPrecipitation deficits can also cause drought, which is a prolonged period of little to no rainfall. Droughts have impacts on the environment and humans, at times causing a chain reaction. For example, California had a drought from 2012 to 2014. While it isn’t uncommon for California to have periods of low precipitation, that with a combination of sustained record high temperatures created severe water shortages. The drought subsequently dried out rivers which hosted populations of the Chinook salmon, affecting the population. That in turn affected Native American tribes food supply."
  },
  {
    "objectID": "wsim-gldas-acquisition.html#reading-the-data",
    "href": "wsim-gldas-acquisition.html#reading-the-data",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Reading the Data",
    "text": "Reading the Data\n\n\n\n\n\n\n\n\nCoding Review\n\n\n\nThis lesson uses the stars, sf, dplyr, and lubridate packages. If you’d like to learn more about the functions used in this lesson you can use the help guides on their package websites.\n\n\nFirst, install and load the R packages required for this exercise:\n\npackages_to_check <- c(\"stars\", \"sf\", \"lubridate\", \"cubelyr\", \"lubridate\")\n\n# Check and install packages\nfor (package_name in packages_to_check) {\n  if (!package_name %in% rownames(installed.packages())) {\n    install.packages(package_name)\n    cat(paste(\"Package\", package_name, \"installed.\\n\"))\n  } else {\n    cat(paste(\"Package\", package_name, \"is already installed.\\n\"))\n  }\n  library(package_name, character.only = TRUE)\n}\n\nOnce you’ve completed the download and placed the .nc into your working directory read in the file with the stars::read_stars() function.\n\n# proxy = TRUE will limit memory useage but does \n# not always work with certain downstream processing functions\n\nwsim_gldas_anoms <- stars::read_stars(\"composite_12mo.nc\", proxy = FALSE)\n\ndeficit, deficit_cause, surplus, surplus_cause, both, \n\nprint(wsim_gldas_anoms)\n\nstars object with 3 dimensions and 5 attributes\nattribute(s), summary of first 1e+05 cells:\n               Min.    1st Qu.    Median       Mean    3rd Qu.      Max.  NA's\ndeficit         -60 -60.000000 -35.61333 -34.465782  -8.279592  41.69147 94083\ndeficit_cause     1 129.000000 129.00000 121.503600 129.000000 129.00000     0\nsurplus         -60  -7.275392  -2.70342  -4.822883   2.431405  60.00000 94088\nsurplus_cause     1 129.000000 129.00000 121.456230 129.000000 129.00000     0\nboth              0   0.000000   0.00000   6.850258   0.000000  60.00000 94088\ndimension(s):\n     from   to offset delta  refsys                    values x/y\nx       1 1440   -180  0.25  WGS 84                      NULL [x]\ny       1  600     90 -0.25  WGS 84                      NULL [y]\ntime    1  793     NA    NA POSIXct 1948-12-01,...,2014-12-01    \n\n\nThe print command gives some basic information. The outputs tells us we have 5 attributes (deficit, deficit_cause, surplus, surplus_cause, both) and 3 dimensions. The first 2 dimensions are the spatial extents (x/y–longitude/latitude) and time is the 3rd dimension.\nThis means the total number of individual raster layers in this NetCDF is 4020 (5 attributes x 804 time steps/months)."
  },
  {
    "objectID": "wsim-gldas-acquisition.html#attribute-selection",
    "href": "wsim-gldas-acquisition.html#attribute-selection",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Attribute Selection",
    "text": "Attribute Selection\nWe can start paring this down by subsetting for just deficits (drought).\n\nnames(wsim_gldas_anoms)\n\n[1] \"deficit\"       \"deficit_cause\" \"surplus\"       \"surplus_cause\"\n[5] \"both\"         \n\nwsim_gldas_anoms <- wsim_gldas_anoms['deficit']"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#time-selection",
    "href": "wsim-gldas-acquisition.html#time-selection",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Time Selection",
    "text": "Time Selection\nSpecifying a temporal range of interest will free up more space. We’ll grab every year for 2000-2014. This can be accomplished by generating a sequence for every year between December 2000 and December 2014, and then passing that vector of dates to filter.\n\n# generate a vector of dates for subsetting\nkeeps<-seq(lubridate::ymd(\"2000-12-01\"),\n           lubridate::ymd(\"2014-12-01\"), \n           by = \"year\")\n#change data type to POSIXct\nkeeps <- as.POSIXct(keeps)\n# filter using that vector\nwsim_gldas_anoms <- dplyr::filter(wsim_gldas_anoms, time %in% keeps)\n\nprint(wsim_gldas_anoms)\n\nstars object with 3 dimensions and 1 attribute\nattribute(s), summary of first 1e+05 cells:\n         Min.  1st Qu.    Median      Mean   3rd Qu.     Max.  NA's\ndeficit   -60 -14.7116 -7.280078 -12.64074 -3.486546 4.991005 94083\ndimension(s):\n     from   to offset delta  refsys                    values x/y\nx       1 1440   -180  0.25  WGS 84                      NULL [x]\ny       1  600     90 -0.25  WGS 84                      NULL [y]\ntime    1   15     NA    NA POSIXct 2000-12-01,...,2014-12-01    \n\n\nNow we’re down to a single attribute (“both”) with 15 time-steps. We can take a look at the first 6 years by passing the object through slice and then into plot.\n\nwsim_gldas_anoms |>\n  dplyr::slice(index = 1:6, along = \"time\") |>\n  plot(key.pos = 1, breaks = c(0, -5, -10, -20, -30, -50), key.lab = \"Deficit\")\n\n\n\n\nAlthough we’ve pared it down to a single attribute with a restricted time period of interest, we can take it a step further and reduce the spatial extent to a country or state of interest."
  },
  {
    "objectID": "wsim-gldas-acquisition.html#spatial-selection",
    "href": "wsim-gldas-acquisition.html#spatial-selection",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Spatial Selection",
    "text": "Spatial Selection\nWe can spatially crop the raster stack with a few different methods. Options include using a bounding box (xmin, ymin, xmax, ymax), another raster object, or a vectorized boundary like a shapefile or geojson.\nUsing a vector boundary is one of the more common geoprocessing tasks. In this example we’ll pull a geojson of the United States from the geoBoundaries API. You can also download vectorized boundaries directly from .\nThe call to geoBoundaries’ API is pretty simple:\n“https://www.geoboundaries.org/api/current/gbOpen/ISO3C/LEVEL/”\nWe adjust the bolded components of the URL address to specify the country we want using the ISO 3 Character Country Code (USA) and the desired Administrative Level (ADM1).\n\nusa <- httr::GET(\"https://www.geoboundaries.org/api/current/gbOpen/USA/ADM1/\")\n\nAfter the GET call, we have to translate the content.\n\nusa <- httr::content(usa)\n\nnames(usa)\n\n [1] \"boundaryID\"                \"boundaryName\"             \n [3] \"boundaryISO\"               \"boundaryYearRepresented\"  \n [5] \"boundaryType\"              \"boundaryCanonical\"        \n [7] \"boundarySource\"            \"boundaryLicense\"          \n [9] \"licenseDetail\"             \"licenseSource\"            \n[11] \"boundarySourceURL\"         \"sourceDataUpdateDate\"     \n[13] \"buildDate\"                 \"Continent\"                \n[15] \"UNSDG-region\"              \"UNSDG-subregion\"          \n[17] \"worldBankIncomeGroup\"      \"admUnitCount\"             \n[19] \"meanVertices\"              \"minVertices\"              \n[21] \"maxVertices\"               \"meanPerimeterLengthKM\"    \n[23] \"minPerimeterLengthKM\"      \"maxPerimeterLengthKM\"     \n[25] \"meanAreaSqKM\"              \"minAreaSqKM\"              \n[27] \"maxAreaSqKM\"               \"staticDownloadLink\"       \n[29] \"gjDownloadURL\"             \"tjDownloadURL\"            \n[31] \"imagePreview\"              \"simplifiedGeometryGeoJSON\"\n\n\nThe parsed content object contains 32 components. Item 29 is a direct link to the geojson file (gjDownloadURL). Read that in and check the visuals.\n\nusa <- sf::st_read(usa$gjDownloadURL)\n\nReading layer `geoBoundaries-USA-ADM1' from data source \n  `https://github.com/wmgeolab/geoBoundaries/raw/9469f09/releaseData/gbOpen/USA/ADM1/geoBoundaries-USA-ADM1.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 56 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1489 ymin: -14.54869 xmax: 179.7785 ymax: 71.36516\nGeodetic CRS:  WGS 84\n\nplot(sf::st_geometry(usa))\n\n\n\n\nThis looks good, but it includes all United States territories. For simplicity, we can get it down to only the contiguous United States.\n\ndrops<-\n  c(\"Alaska\", \"Hawaii\", \n    \"American Samoa\",\n    \"Puerto Rico\",\n    \"Commonwealth of the Northern Mariana Islands\", \n    \"Guam\", \n    \"United States Virgin Islands\")\n\nusa<-usa[!(usa$shapeName %in% drops),]\n\nplot(sf::st_geometry(usa))\n\n\n\n\nWe can take this a step further and select a target state.\n\ntexas <- usa[usa$shapeName == \"Texas\",]\n\nplot(sf::st_geometry(texas))\n\n\n\n\nFrom here we can crop the WSIM GLDAS raster stack by indexing it with the stored boundary of Texas.\n**Texas, in 2011, experienced a severe drought which caused rivers to dry up and lakes to reach historic low levels. The drought cost farmers and ranchers an estimated $8 billion in losses. Furthermore, the dry conditions fueled a series of wildfires across the state in early September.\n\nwsim_gldas_anoms_tex <- wsim_gldas_anoms[texas]\n\nFor a final visual check we’ll take the last time-step in the WSIM-GLDAS dataset (15/December, 2014) and plot it with an overlay of the Texas boundary.\n\nwsim_gldas_anoms_tex |>\n  dplyr::slice(index = 15, along = \"time\") |>\n  plot(reset = FALSE, breaks = c(0,-1,-2,-3,-4,-5))\n\nplot(sf::st_geometry(texas),\n     add = TRUE,\n     lwd = 3,\n     fill = NA,\n     border = 'purple')\n\n\n\n\nThe subsetted dataset may be written to disk, and saved for future modules.\n\nstars::write_mdim(wsim_gldas_anoms_tex, \"wsim_gldas_tex.nc\")\n\nThe size of the pre-processed dataset is 1.6 MB compared to the original dataset of 1.7 GB. This is much more manageable in cloud environments, workshops, and git platforms."
  },
  {
    "objectID": "wsim-gldas-vis.html",
    "href": "wsim-gldas-vis.html",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "",
    "text": "Write the actual code and narrative.\nDetermine the region and time period of focus to draw in our use cases/human focused stories.\nDetermine the method of exploration.\n\nMimic our process?\n\n12 month integration panels of the CON USA from 2000-2014 to identify areas of interest.\nZoom in to locations of interest and switch to 1-month integration for the years identified in the previous step."
  },
  {
    "objectID": "wsim-gldas-vis.html#to-do",
    "href": "wsim-gldas-vis.html#to-do",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "",
    "text": "Write the actual code and narrative.\nDetermine the region and time period of focus to draw in our use cases/human focused stories.\nDetermine the method of exploration.\n\nMimic our process?\n\n12 month integration panels of the CON USA from 2000-2014 to identify areas of interest.\nZoom in to locations of interest and switch to 1-month integration for the years identified in the previous step."
  },
  {
    "objectID": "wsim-gldas-vis.html#introduction",
    "href": "wsim-gldas-vis.html#introduction",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Introduction",
    "text": "Introduction\nA raster is a grid of geographic data which has information stored per pixel. Vectors are a collection or a list of numbers. Vectors can be used to store coordinates, which can then be used to extract information from a pixel in the raster for analysis, such as a time series. Rasters can store many types of information, such as precipitation anomaly data, which can show rainfall deficits or surpluses.\nAn anomaly is described as a deviation from the long term average over a period and region. Precipitation anomalies can cause drought, which is a prolonged period of little to no rainfall. Droughts have impacts on the environment and humans, at times causing a chain reaction. For example, California had a drought in 2014 that subsequently dried out rivers which hosted populations of the Chinook salmon, affecting the population. That in turn affected Native American tribes food supply.\nIn this vignette, you will be combining the basic plot() function with sf functions to plot singular attributes, and using more advanced plotting functions such as ggplot() for plotting histograms, multi-panel plots, and a time series."
  },
  {
    "objectID": "wsim-gldas-vis.html#setup",
    "href": "wsim-gldas-vis.html#setup",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Setup",
    "text": "Setup"
  },
  {
    "objectID": "wsim-gldas-vis.html#load-data",
    "href": "wsim-gldas-vis.html#load-data",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Load Data",
    "text": "Load Data\nWe’ll start again with the WSIM-GLDAS 12 month integration anomaly file from SEDAC and quickly subset it to the continental United States.\n\n\nCode\n# generate a vector of dates for subsetting\nwsim_gldas &lt;- stars::read_stars(\"composite_anom_12mo.nc\", proxy = FALSE)\n\n\ndeficit, deficit_cause, surplus, surplus_cause, both, \n\n\nCode\nkeeps&lt;-seq(lubridate::ymd(\"2000-12-01\"),\n           lubridate::ymd(\"2014-12-01\"), \n           by = \"year\")\n\n# filter using that vector\nwsim_gldas &lt;- dplyr::filter(wsim_gldas, time %in% keeps)\n\n# you may want to clear your memory if your system is limited\ngc()\n\n\n           used  (Mb) gc trigger    (Mb)   max used    (Mb)\nNcells  1005361  53.7    1676214    89.6    1676214    89.6\nVcells 66544414 507.7 3291944693 25115.6 3492734447 26647.5\n\n\nCode\n# subset for deficit\nwsim_deficit &lt;- wsim_gldas['deficit']\n\nusa &lt;- httr::GET(\"https://www.geoboundaries.org/api/current/gbOpen/USA/ADM1/\")\nusa &lt;- httr::content(usa)\nusa &lt;- sf::st_read(usa$gjDownloadURL)\n\n\nReading layer `geoBoundaries-USA-ADM1' from data source \n  `https://github.com/wmgeolab/geoBoundaries/raw/9469f09/releaseData/gbOpen/USA/ADM1/geoBoundaries-USA-ADM1.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 56 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1489 ymin: -14.54869 xmax: 179.7785 ymax: 71.36516\nGeodetic CRS:  WGS 84\n\n\nCode\ndrops&lt;-\n  c(\"Alaska\", \"Hawaii\", \n    \"American Samoa\",\n    \"Puerto Rico\",\n    \"Commonwealth of the Northern Mariana Islands\", \n    \"Guam\", \n    \"United States Virgin Islands\")\n\nusa&lt;-usa[!(usa$shapeName %in% drops),]\nwsim_deficit_usa&lt;-wsim_deficit[usa]\n\n\nNow we’ll verify this with print() and plot().\n\nprint(wsim_deficit_usa)\n\nstars object with 3 dimensions and 1 attribute\nattribute(s):\n         Min.   1st Qu.     Median       Mean     3rd Qu.     Max.   NA's\ndeficit  -100 -1.271282 -0.7135856 -0.8666337 -0.05214565 3.489938 153810\ndimension(s):\n     from  to offset delta  refsys                    values x/y\nx     221 453   -180  0.25  WGS 84                      NULL [x]\ny     163 262     90 -0.25  WGS 84                      NULL [y]\ntime    1  15     NA    NA POSIXct 2000-12-01,...,2014-12-01    \n\n\nThe output shows that we’ve selected a single attribute (‘deficit’) and 15 time-steps in the ‘time’ dimension. Plot only the 14th time step and show the border color as purple, and a lineweight of 3.\n\nwsim_deficit_usa |&gt;\n  dplyr::slice(index = 15, along = \"time\") |&gt;\n  plot(reset = FALSE, breaks = c(0,-5,-10,-20,-40,-50))\n\nplot(sf::st_geometry(usa),\n     add = TRUE,\n     lwd = 3,\n     fill = NA,\n     border = 'purple')"
  },
  {
    "objectID": "wsim-gldas-vis.html#exploratory-histogram",
    "href": "wsim-gldas-vis.html#exploratory-histogram",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Exploratory Histogram",
    "text": "Exploratory Histogram\nCreate histogram of raster values for a single time step.\nGet the values out of the raster and create a histogram.\n\n# filter for the first time-step in the file\nusa1 &lt;-\n  wsim_deficit_usa |&gt; dplyr::slice(time, 1)\n\n# extract the values into a data.frame\nusa1&lt;-as.data.frame(as.numeric(wsim_deficit_usa$deficit))\n\n# appropriately name the values (it was lost in the example)\nnames(usa1)&lt;-\"Deficit\"\n\nCheck the values.\n\nggplot2::ggplot(usa1, ggplot2::aes(Deficit))+\n  ggplot2::geom_histogram(na.rm = TRUE)\n\n\n\n\n\n\n\n\nThere are some bad outliers, we can just zoom into the majority of values by setting x-axis limits.\n\nggplot2::ggplot(usa1, ggplot2::aes(Deficit))+\n  ggplot2::geom_histogram(na.rm = TRUE)+\n  ggplot2::xlim(c(-10,0))\n\n\n\n\n\n\n\n\nExtreme values or other items of note might require additional visualization or other data exploration."
  },
  {
    "objectID": "wsim-gldas-vis.html#multi-panel-time-series",
    "href": "wsim-gldas-vis.html#multi-panel-time-series",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Multi-Panel Time Series",
    "text": "Multi-Panel Time Series\nCreate a multipanel time series of 12 month integration CONUSA; similar to what we used to identify our case studies. Each panel will represent 1 year.\nLoad in a CONUSA geojson from geoBoundaries. Copy methods from previous vignette.\n\n# the histogram can be studied to properly choose breaks. For example, try plotting the histogram from (-10,10) to determine where values lie between. Breaks chosen are [-5, -3, -1, 0, 1, 3, 5] from studying the histogram.\n\nwsim_deficit_usa |&gt;\n  dplyr::slice(index = 1:14, along = \"time\") |&gt;\n  plot(reset = FALSE,\n       col = leg_colors&lt;-c(\n    '#9B0039',\n    # -50 to -40\n    '#D44135',\n    # -40 to -20\n    '#FF8D43',\n    # -20 to -10\n    '#FFC754',\n    # -10 to -5\n    '#FFEDA3',\n    # -5 to -3\n    '#FFFFFF'), breaks = c(-5,-3,-1,0,1,3,5))\n\n\n\n\n\n\n\n\nPlotting without breaks produces a similar but different map.\n\nwsim_deficit_usa |&gt;\n  dplyr::slice(index = 1:14, along = \"time\") |&gt;\n  plot(reset = FALSE,\n       col = leg_colors&lt;-c(\n    '#9B0039',\n    # -50 to -40\n    '#D44135',\n    # -40 to -20\n    '#FF8D43',\n    # -20 to -10\n    '#FFC754',\n    # -10 to -5\n    '#FFEDA3',\n    # -5 to -3\n    '#FFFFFF'))\n\n\n\n\n\n\n\n\nOnce hot spots are easily identified pick a region of interest to zoom in on using the 1 month integration dataset.\nLoad in the 1 month integration dataset and subset/index the dataset to the region of interest (copy code from previous vignette). Use dplyr::slice or other method to pull out just the 12 months from the year of interest. Code demonstrating these techniques in previous vignette.\n\ngc()\n\n           used  (Mb) gc trigger    (Mb)   max used    (Mb)\nNcells  1346806  72.0    2608071   139.3    2608071   139.3\nVcells 81180469 619.4 2106844604 16074.0 3492734447 26647.5\n\nwsim_gldas_1mo &lt;- stars::read_stars(\"composite_anom_1mo.nc\", proxy = FALSE)\n\ndeficit, deficit_cause, surplus, surplus_cause, both, \n\nprint(wsim_gldas_1mo)\n\nstars object with 3 dimensions and 5 attributes\nattribute(s), summary of first 1e+05 cells:\n               Min.     1st Qu.      Median         Mean     3rd Qu.       Max.\ndeficit        -100  -1.8314584  -0.2373874  -1.26453645  -0.2373874   1.896493\ndeficit_cause     1 129.0000000 129.0000000 112.90956000 129.0000000 129.000000\nsurplus        -100  -0.9671488  -0.7329655  -0.95631468  -0.6206152   2.384447\nsurplus_cause     1 129.0000000 129.0000000 127.37130000 129.0000000 129.000000\nboth              0   0.0000000   0.0000000   0.03784493   0.0000000   2.384447\n                NA's\ndeficit        87340\ndeficit_cause      0\nsurplus        98724\nsurplus_cause      0\nboth           98724\ndimension(s):\n     from   to offset delta  refsys                    values x/y\nx       1 1440   -180  0.25  WGS 84                      NULL [x]\ny       1  600     90 -0.25  WGS 84                      NULL [y]\ntime    1  804     NA    NA POSIXct 1948-01-01,...,2014-12-01    \n\n# subset for USA\nwsim_gldas_1mo&lt;-wsim_gldas_1mo[usa]\n\n# subset for deficit\nwsim_gldas_1mo &lt;- wsim_gldas_1mo['deficit']\n\n# create a new sequence of dates, this time monthly, for the chosen year of 2011\nkeeps3&lt;-seq(lubridate::ymd(\"2011-01-01\"),\n           lubridate::ymd(\"2011-12-01\"), \n           by = \"month\")\n\nwsim_gldas_1mo &lt;- dplyr::filter(wsim_gldas_1mo, time %in% keeps3)\n\nCreate a multi-panel figure with each panel representing 1 month to identify the most intense months of drought or flooding. Starting with this one maybe use ggplot and a nice palette, legend, and panel headings. Will probably have to use some sort of faceting to make individual panels.\n\n# turn into dataframe\ndf_wsim_gldas_1mo &lt;-as.data.frame(wsim_gldas_1mo, xy = TRUE) \n\nggplot2::ggplot(data = df_wsim_gldas_1mo) +\n  ggplot2::geom_raster(ggplot2::aes(x = x, y = y, fill = deficit)) +\n  ggplot2::scale_fill_viridis_c(limits = c(-5, 5), option = \"magma\") +\n  ggplot2::theme_void() +\n  ggplot2::theme(legend.position = \"bottom\") +\n  ggplot2::facet_wrap(time ~ .)\n\n\n\n\n\n\n\n\nVisualize an individual cell with particular extreme or maybe volatile values. Use Google Maps to identify the latitude/longitude of a place of interest. Maybe an urban center or other important location in the region that suffered from the extreme event.\nCreate a vector with the point location.\n\n# vector of coordinates for Austin, Texas\ncoords &lt;- c(-97.7431, 30.2672)\n\n# create a stars object with point coordinates where 'sf::st_sfc()' is used to create a geometry list column and add a coordinate reference system. 'sf::st_points()' is within that function to turn the coords vector into a point. 'sf:: st_crs()' and 'stars::st_dimensions()'  respectively retrieves the coordinate reference system and the dimensions of wsim_gldas_1mo to ensure that the final values in point_stars is the same reference system and shape. \n\npoint_stars &lt;- sf::st_sfc(sf::st_point(coords), crs = sf::st_crs(wsim_gldas_1mo),\n                      dim = names(stars::st_dimensions(wsim_gldas_1mo)))\n\nUse stars::extract to extract raster values in the stack at the point location.\n\nextracted_vals &lt;- stars::st_extract(wsim_gldas_1mo, point_stars)\n\nThe resulting data frame of time series values should be inspected. It may also need to be converted from wide format to long format so it may be plotted in ggplot. Use either pivot wider/longer from dplyr or cast/melt from data.table.\n\n# convert to dataframe\nextracted_df &lt;- as.data.frame(extracted_vals)\n\nprint(extracted_df)\n\n                   geometry       time    deficit\n1  POINT (-97.7431 30.2672) 2011-01-01 -0.4095472\n2  POINT (-97.7431 30.2672) 2011-02-01 -0.5968595\n3  POINT (-97.7431 30.2672) 2011-03-01 -1.2968605\n4  POINT (-97.7431 30.2672) 2011-04-01 -2.2969067\n5  POINT (-97.7431 30.2672) 2011-05-01 -1.7285879\n6  POINT (-97.7431 30.2672) 2011-06-01 -1.7681433\n7  POINT (-97.7431 30.2672) 2011-07-01 -1.3872044\n8  POINT (-97.7431 30.2672) 2011-08-01 -2.1615715\n9  POINT (-97.7431 30.2672) 2011-09-01 -2.0129523\n10 POINT (-97.7431 30.2672) 2011-10-01 -1.1885774\n11 POINT (-97.7431 30.2672) 2011-11-01 -1.1728865\n12 POINT (-97.7431 30.2672) 2011-12-01 -0.7794579\n\n\nOnce in the proper format, plot using ggplot.\n\nggplot2::ggplot(extracted_df, ggplot2::aes(x = time, y = deficit)) + ggplot2::geom_line()\n\n\n\n\n\n\n\n\nTexas, in 2011, experienced a severe drought which caused rivers to dry up and lakes to reach historic low levels. The drought cost farmers and ranchers an estimated $8 billion in losses. Furthermore, the dry conditions fueled a series of wildfires across the state in early September. Which months experienced the most severe drought?"
  },
  {
    "objectID": "wsim-gldas-vis.html#use-case-background",
    "href": "wsim-gldas-vis.html#use-case-background",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Use Case Background",
    "text": "Use Case Background\nNow that we’ve keyed in on a particular event, bring in the backup information we’ve collected to discuss what actually happened."
  },
  {
    "objectID": "wsim-gldas-vis.html#point-location-time-series",
    "href": "wsim-gldas-vis.html#point-location-time-series",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Point Location Time Series",
    "text": "Point Location Time Series\nVisualize an individual cell with particular extreme or maybe volatile values. Use Google Maps to identify the latitude/longitude of a place of interest. Maybe an urban center or other important location in the region that suffered from the extreme event.\nCreate a vector with the point location.\n\nUse stars::extract to extract raster values in the stack at the point location.\n\nThe resulting data frame of time series values should be inspected. It may also need to be converted from wide format to long format so it may be plotted in ggplot. Use either pivot wider/longer from dplyr or cast/melt from data.table.\n\nOnce in the proper format, plot using ggplot."
  },
  {
    "objectID": "wsim-gldas-vis.html#population-exposure-plot",
    "href": "wsim-gldas-vis.html#population-exposure-plot",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Population Exposure Plot",
    "text": "Population Exposure Plot\nUse Gridded Population of the World and exactextractr to determine the number of people exposed to a given anomaly for each month of the year.\nGridded Population of the World is a dataset group in SEDAC which models the distribution of the global human population through counts and densities on a raster. These estimates are available for the years of 2000, 2005, 2015 and 2020. The Population Count dataset will be used for this example, and can be found here. [https://sedac.ciesin.columbia.edu/data/collection/gpw-v4]\n‘exactextractr’ is an R package that summarizes raster values over groupings, or zones, also known as zonal statistics. Zonal statistics help in assessing the statistical characteristics of a certain region. The package can be used to sum all the cells in a polygon, i.e. a region; other functions include computing the mean, median, and other types of statistics. More information on the package can be found here [https://github.com/isciences/exactextractr].\nLoad in GPW data and the exactextractr package\n\ngpw &lt;- stars::read_stars(\"gpw_v4_population_count_rev11_2020_30_sec.tif\", proxy = FALSE)\nprint(gpw)\n\nstars object with 2 dimensions and 1 attribute\nattribute(s), summary of first 1e+05 cells:\n                                Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\ngpw_v4_population_count_rev...    NA      NA     NA  NaN      NA   NA 1e+05\ndimension(s):\n  from    to offset     delta refsys point x/y\nx    1 43200   -180  0.008333 WGS 84 FALSE [x]\ny    1 21600     90 -0.008333 WGS 84 FALSE [y]\n\ngpw_df &lt;-as.data.frame(gpw)\n\nPerform the time series zonal summary.\nThis might be a bit tricky; been a while for me. Have to look up the proper code. Dan has good examples on the exactextractr package website.\nResulting data.frame will probably need to be transformed to long (just like before), so it can be plotted.\nNow plot the data in ggplot. I have some existing code I can pull to help with the plotting–or at least make it fancy."
  },
  {
    "objectID": "LANCE_MODIS_NRT_GlobalFlood_MCDWD.html",
    "href": "LANCE_MODIS_NRT_GlobalFlood_MCDWD.html",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "The MODIS/Aqua+Terra Global Flood Product L3 Near Real Time (NRT) 250m Global Flood Product (MCDWD_L3_NRT) (beta) provides daily maps of flooding globally. The product is provided over 3 compositing periods (1-day, 2-day, and 3-day) to minimize the impact of clouds and more rigorously identify flood water (the best composite will depend on the cloudiness for a particular event).\n\nNASA EARTHDATA\nCRM SEARCH\n\npackages_to_check &lt;- c(\"stars\", \"httr\", \"jsonlite\", \"tmap\")\n\n# Check and install packages\nfor (package_name in packages_to_check) {\n  if (!package_name %in% rownames(installed.packages())) {\n    install.packages(package_name)\n    cat(paste(\"Package\", package_name, \"installed.\\n\"))\n  } else {\n    cat(paste(\"Package\", package_name, \"is already installed.\\n\"))\n  }\n  library(package_name, character.only = TRUE)\n}\n\nPackage stars is already installed.\nPackage httr is already installed.\nPackage jsonlite is already installed.\nPackage tmap is already installed.\n\n\n\n#in case tmap does not install\n#remotes::install_github('r-tmap/tmap')\n\n\n\n\n\n\nBased on availability, edit the year_day variable YYYY-DD. Example: ‘2022-01’\n\n#add the year and date you want to search for (YYYY-DD, 2022-01)\nyear_day &lt;- '2023-336'\n\n\n\n\n\nBased on availability, edit the tile_code variable:\n\n#add tile code from the map above (written as h00v00)\ntile_code &lt;- 'h05v05'\n\nThis is the NRT Flood F3 (MCDWD_L3_F3) API URL:\n\nAPI_URL &lt;- paste0('https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=')\n\nWe can combine the API URL above with the year_day provided and print the available datasets:\n\n#pasting together URL and year_day\nurl &lt;- paste0(API_URL, year_day)\nprint(url)\n\n[1] \"https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=2023-336\"\n\n\n\n\n\n\nAccess the NASA Earthdata with the GET function:\n\nif(!file.exists(\"modis_nrt_flood.nc\")) {\n  # Make the GET request\n  response &lt;- httr::GET(url)\n  # Check response status from the GET function and check the contents from the parsed data.\n  print(response)\n  if (http_status(response)$category == \"Success\") {\n    # Parse the response JSON\n    data &lt;- content(response, as = \"text\", encoding = \"UTF-8\")\n    data_parsed &lt;- jsonlite::fromJSON(data)\n    #filter for the tile code\n    content_items &lt;- data_parsed$content[grepl(tile_code, data_parsed$content$name, ignore.case = TRUE), ]\n    #check the content items\n    print(content_items)\n    #Select the URL from the 'downloadsLink' column in the content_items list: \n    download_link &lt;- content_items$downloadsLink\n    print(download_link)\n    \n    stars::write_stars(raster_df, \"modis_nrt_flood.nc\")\n   \n  } else {\n    print(\"Request failed with status code\", http_status(response)$status_code)\n  }\n  \n} else{\n  download_link &lt;- \"modis_nrt_flood.nc\"\n}\n\nUse the “read_stars()” function from the “stars” R Library to read the geoTiff raster. The raster is assigned to the “x” variable:\n\nraster_df &lt;- stars::read_stars(download_link)\n\nSet the Coordinate reference system (CRS) to “EPSG:4326”\n\nmy_raster &lt;- st_set_crs(raster_df, st_crs(\"EPSG:4326\"))\n\nWarning in `st_crs&lt;-.dimensions`(`*tmp*`, value = value): replacing CRS does\nnot reproject data: use st_transform, or st_warp to warp to a new CRS\n\nst_crs(my_raster)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\nPlot the raster to quickly view it:\n\nplot(my_raster, axes = TRUE)\n\ndownsample set to 3\n\n\n\n\n\n\n\nRefer to the MODIS NRT Global Flood Product User Guide for more information.\nNRT Flood data has 5 classifications:\n\n\n\nCode\nDefinition\n\n\n\n\n0\nNo Water\n\n\n1\nSurface Water\n\n\n2\nRecurring flood1\n\n\n3\nFlood (unusual)\n\n\n255\nInsufficient data\n\n\n\nCreate a classified legend; however, the NRT Flood data is stored in decimal numbers (aka floating-point). Create class breaks dividing the data by these breaks, and corresponding colors and labels:\n\nclass_breaks &lt;- c(-Inf, 0.1, 1.1, 2.1, 3.1)\ncolors &lt;- c( \"gray\", \"blue\", \"yellow\",\"red\")\n\nlabels = c(\"0: No Water\", \"1: Surface Water\", \"2: Recurring flood\", \"3: Flood (unusual)\")\n\nAdd a title for the plot that includes the year, day of year, and tile code:\n\ntitle = paste(\"NRT Flood\", year_day, tile_code)\n\nGenerate a plot from the tmap library using the tm_shape() function. With style as “cat,” meaning categorical. T\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n## tmap mode set to plotting\ntm_shape(my_raster, style=\"cat\" )+\n  tm_raster(palette = c(colors), \n  title = title, \n  breaks = class_breaks,\n  labels = labels )+\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_layout(legend.outside = TRUE)\n\nstars object downsampled to 1000 by 1000 cells. See tm_shape manual (argument raster.downsample)"
  },
  {
    "objectID": "LANCE_MODIS_NRT_GlobalFlood_MCDWD.html#modis-nrt-global-flood-product",
    "href": "LANCE_MODIS_NRT_GlobalFlood_MCDWD.html#modis-nrt-global-flood-product",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "The MODIS/Aqua+Terra Global Flood Product L3 Near Real Time (NRT) 250m Global Flood Product (MCDWD_L3_NRT) (beta) provides daily maps of flooding globally. The product is provided over 3 compositing periods (1-day, 2-day, and 3-day) to minimize the impact of clouds and more rigorously identify flood water (the best composite will depend on the cloudiness for a particular event).\n\nNASA EARTHDATA\nCRM SEARCH\n\npackages_to_check &lt;- c(\"stars\", \"httr\", \"jsonlite\", \"tmap\")\n\n# Check and install packages\nfor (package_name in packages_to_check) {\n  if (!package_name %in% rownames(installed.packages())) {\n    install.packages(package_name)\n    cat(paste(\"Package\", package_name, \"installed.\\n\"))\n  } else {\n    cat(paste(\"Package\", package_name, \"is already installed.\\n\"))\n  }\n  library(package_name, character.only = TRUE)\n}\n\nPackage stars is already installed.\nPackage httr is already installed.\nPackage jsonlite is already installed.\nPackage tmap is already installed.\n\n\n\n#in case tmap does not install\n#remotes::install_github('r-tmap/tmap')\n\n\n\n\n\n\nBased on availability, edit the year_day variable YYYY-DD. Example: ‘2022-01’\n\n#add the year and date you want to search for (YYYY-DD, 2022-01)\nyear_day &lt;- '2023-336'\n\n\n\n\n\nBased on availability, edit the tile_code variable:\n\n#add tile code from the map above (written as h00v00)\ntile_code &lt;- 'h05v05'\n\nThis is the NRT Flood F3 (MCDWD_L3_F3) API URL:\n\nAPI_URL &lt;- paste0('https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=')\n\nWe can combine the API URL above with the year_day provided and print the available datasets:\n\n#pasting together URL and year_day\nurl &lt;- paste0(API_URL, year_day)\nprint(url)\n\n[1] \"https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=2023-336\"\n\n\n\n\n\n\nAccess the NASA Earthdata with the GET function:\n\nif(!file.exists(\"modis_nrt_flood.nc\")) {\n  # Make the GET request\n  response &lt;- httr::GET(url)\n  # Check response status from the GET function and check the contents from the parsed data.\n  print(response)\n  if (http_status(response)$category == \"Success\") {\n    # Parse the response JSON\n    data &lt;- content(response, as = \"text\", encoding = \"UTF-8\")\n    data_parsed &lt;- jsonlite::fromJSON(data)\n    #filter for the tile code\n    content_items &lt;- data_parsed$content[grepl(tile_code, data_parsed$content$name, ignore.case = TRUE), ]\n    #check the content items\n    print(content_items)\n    #Select the URL from the 'downloadsLink' column in the content_items list: \n    download_link &lt;- content_items$downloadsLink\n    print(download_link)\n    \n    stars::write_stars(raster_df, \"modis_nrt_flood.nc\")\n   \n  } else {\n    print(\"Request failed with status code\", http_status(response)$status_code)\n  }\n  \n} else{\n  download_link &lt;- \"modis_nrt_flood.nc\"\n}\n\nUse the “read_stars()” function from the “stars” R Library to read the geoTiff raster. The raster is assigned to the “x” variable:\n\nraster_df &lt;- stars::read_stars(download_link)\n\nSet the Coordinate reference system (CRS) to “EPSG:4326”\n\nmy_raster &lt;- st_set_crs(raster_df, st_crs(\"EPSG:4326\"))\n\nWarning in `st_crs&lt;-.dimensions`(`*tmp*`, value = value): replacing CRS does\nnot reproject data: use st_transform, or st_warp to warp to a new CRS\n\nst_crs(my_raster)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\nPlot the raster to quickly view it:\n\nplot(my_raster, axes = TRUE)\n\ndownsample set to 3\n\n\n\n\n\n\n\nRefer to the MODIS NRT Global Flood Product User Guide for more information.\nNRT Flood data has 5 classifications:\n\n\n\nCode\nDefinition\n\n\n\n\n0\nNo Water\n\n\n1\nSurface Water\n\n\n2\nRecurring flood1\n\n\n3\nFlood (unusual)\n\n\n255\nInsufficient data\n\n\n\nCreate a classified legend; however, the NRT Flood data is stored in decimal numbers (aka floating-point). Create class breaks dividing the data by these breaks, and corresponding colors and labels:\n\nclass_breaks &lt;- c(-Inf, 0.1, 1.1, 2.1, 3.1)\ncolors &lt;- c( \"gray\", \"blue\", \"yellow\",\"red\")\n\nlabels = c(\"0: No Water\", \"1: Surface Water\", \"2: Recurring flood\", \"3: Flood (unusual)\")\n\nAdd a title for the plot that includes the year, day of year, and tile code:\n\ntitle = paste(\"NRT Flood\", year_day, tile_code)\n\nGenerate a plot from the tmap library using the tm_shape() function. With style as “cat,” meaning categorical. T\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n## tmap mode set to plotting\ntm_shape(my_raster, style=\"cat\" )+\n  tm_raster(palette = c(colors), \n  title = title, \n  breaks = class_breaks,\n  labels = labels )+\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_layout(legend.outside = TRUE)\n\nstars object downsampled to 1000 by 1000 cells. See tm_shape manual (argument raster.downsample)"
  },
  {
    "objectID": "LANCE_MODIS_NRT_GlobalFlood_MCDWD.html#footnotes",
    "href": "LANCE_MODIS_NRT_GlobalFlood_MCDWD.html#footnotes",
    "title": "MODIS NRT Global Flood Product",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nValue 2 (Recurring flood) is not populated in the beta release.↩︎"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#outline",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#outline",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Outline",
    "text": "Outline\n\nLearning objectives\nTechnical details\nOpen Science Components"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#presentation-outline",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#presentation-outline",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Presentation Outline",
    "text": "Presentation Outline\n\nModule Goals\nLearning objectives\nOpen Science Components\nTechnical details\nProposed analyses and outputs"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#learning-objectives",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#learning-objectives",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nWe are currently in the early development phases and need to adjust the narrative voice between 3 learning/content components.\n\nWater resources\nTechnical data\nTechnical coding\n\n\nOne goal of these two days is to solicit feedback regarding objectives like these."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#wsim-gldas",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#wsim-gldas",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "WSIM-GLDAS",
    "text": "WSIM-GLDAS\nWSIM-GLDAS is an open source dataset that characterizes surpluses and deficits of freshwater and the parameters determining these anomalies.\n\n\n\nGlobally rasterized dataset issued monthly for 1948-2014\nComposite surplus/deficit anomalies\nMultitude of additional metrics and integration periods\nFreely available on SEDAC\n\n\n\n\n\n\n\n\n\n\nThe datasets are available as multidimensional netCDF files"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#open-science-components",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#open-science-components",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Open Science Components",
    "text": "Open Science Components\nLike all other components of the SCHOOL project, the water resource modules are entirely open source.\n\n\n\nOpen source computing (R, Rstudio, VS Code, QGIS, etc.)\nOpen source datasets; freely available and well documented\nOpen source development\nOpen source “results” on GitHub Pages\n\n\n\n\n\n\n\nDevelopment components are also open science. We’re bringing along research assistants with descriptive vignette templates/lessons\nI’m developing on a mix of tech stacks, but it’s important to make sure our modules work on Linux/Ubuntu"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#water-resource-objectives",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#water-resource-objectives",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Water Resource Objectives",
    "text": "Water Resource Objectives\nThese include introducing the domain knowledge and human narrative that can be derived from these datasets.\n\nUnderstanding the socioeconomic and environmental impacts of droughts and floods.\nExploring drought and flooding events in areas of interest to you and learning about the impacts to local water supplies, agriculture, recreation, and tourism.\nBasic background on the water cycle."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#technical-data-objectives",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#technical-data-objectives",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Technical Data Objectives",
    "text": "Technical Data Objectives\n\nWhat does water resource data “look” like?\nWhere do you find it and how do you get it?"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#coding-objectives",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#coding-objectives",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Coding Objectives",
    "text": "Coding Objectives\nAre we interested at all in teaching people how to code? Unlikely but then how do you address all the code.\n# generate a vector of dates for subsetting\nkeeps&lt;-seq(lubridate::ymd(\"2000-01-01\"),\n           lubridate::ymd(\"2014-12-01\"), \n           by = \"month\")\n           \n# filter using that vector\nwsim_gldas_anoms &lt;- dplyr::filter(wsim_gldas_anoms, time %in% keeps)\n\n# verify the time dimension was properly subsetted\nprint(wsim_gldas_anoms)\n\n# do a visual check with the first 6 time-steps\nwsim_gldas_anoms |&gt;\n  dplyr::slice(index = 1:6, along = \"time\") |&gt;\n  plot(key.pos = 1)\n\n\n\nSEDAC Workshop on Open Science"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#narrative-objectives",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#narrative-objectives",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Narrative Objectives",
    "text": "Narrative Objectives\nWe are currently in the early development phases and need to adjust the narrative voice between 3 learning/content components.\n\nWater resources\nTechnical data\nTechnical coding\n\n\nOne goal of these two days is to solicit feedback regarding objectives like these."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#water-resource-narrative",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#water-resource-narrative",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Water Resource Narrative",
    "text": "Water Resource Narrative\nThese include introducing the domain knowledge and human narrative that can be derived from these datasets.\n\n\n\nUnderstanding the socioeconomic and environmental impacts of droughts and floods.\nExploring drought and flooding events in areas of interest to you and learning about the impacts to local water supplies, agriculture, recreation, and tourism.\nBasic background on the water cycle."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#technical-data-narrative",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#technical-data-narrative",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Technical Data Narrative",
    "text": "Technical Data Narrative\n\nWhat does water resource data “look” like?\nWhere do you find it and how do you get it?\n\n\n\n\n\n\n\n\nHere we have a complex structure with data cubes/netcdf, but other lessons in the module and other modules will feature a variety of data structures"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#coding-narrative",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#coding-narrative",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Coding Narrative",
    "text": "Coding Narrative\nAre we interested at all in teaching people how to code? Unlikely but then how do you address all the code.\n# generate a vector of dates for subsetting\nkeeps&lt;-seq(lubridate::ymd(\"2000-01-01\"),\n           lubridate::ymd(\"2014-12-01\"), \n           by = \"month\")\n           \n# filter using that vector\nwsim_gldas_anoms &lt;- dplyr::filter(wsim_gldas_anoms, time %in% keeps)\n\n# verify the time dimension was properly subsetted\nprint(wsim_gldas_anoms)\n\n# do a visual check with the first 6 time-steps\nwsim_gldas_anoms |&gt;\n  dplyr::slice(index = 1:6, along = \"time\") |&gt;\n  plot(key.pos = 1)"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#outputs-and-analyses",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#outputs-and-analyses",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Outputs and Analyses",
    "text": "Outputs and Analyses\nWhatever the chosen narrative voice and content, we hope to bring greater understanding for each module through visualizations and analysis. The WSIM-GLDAS water resource modules will achieve this by creating:\n\nNational and regional 12 month integration composite surplus/deficit maps\nTime series illustrations of point locations\nPopulation exposure time series figures and tables"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#composite-surplus-and-deficit-maps",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#composite-surplus-and-deficit-maps",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Composite Surplus and Deficit Maps",
    "text": "Composite Surplus and Deficit Maps\nTwelve month integration maps illustrate the observed drought or flooding of an area relative to a long term baseline period.\n\n\n\n\n\n\n\nLonger term integration plots quickly summarize climate trends for large areas, and help users identify areas of interest."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#location-of-interest",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#location-of-interest",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Location of Interest",
    "text": "Location of Interest\nPoint location time series figures illustrate long term trends for a single location on a month to month basis.\n\n\n\n\n\n\n\nThese plots can really bring the impacts of droughts and floods to a specific point; your home, your school, etc."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#population-exposure",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#population-exposure",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Population Exposure",
    "text": "Population Exposure\nPopulation exposure plots and tables help illustrate the sociological impacts of droughts and floods.\n\n\n\n\n\n\n\nCommonplace to show maps depicting extreme heat or floods in a particular area, but does anyone actually live there?"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#composite-surplus-and-deficit-maps-cont.",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#composite-surplus-and-deficit-maps-cont.",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Composite Surplus and Deficit Maps (cont.)",
    "text": "Composite Surplus and Deficit Maps (cont.)\nNow you can zoom in on an area of interest with a monthly time series."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#current-drafts",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#current-drafts",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Current Drafts",
    "text": "Current Drafts\nAlthough the module and lesson structure is yet to be finalized, we have some rough drafts in place that demonstrate the baseline technical workflow and present a template for dev assistants.\n\nAcquiring and Subsetting WSIM-GLDAS\nVisualizing and Exploring WSIM-GLDAS\nMODIS Near Real Time Flood Data\nThis presentation is also online"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#an-open-process",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#an-open-process",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "An Open Process",
    "text": "An Open Process\nThis is an open process reliant on feedback from our:\n\nSubject matter experts\nProject managers\nDevelopment team\nResearch assistants\nUsers and collaborators like you\n\nWe always welcome comments, contributors, and all types of feedback in person, through the TOPS network, and our GitHub repositories."
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#acknowledgements-questions",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#acknowledgements-questions",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Acknowledgements & Questions",
    "text": "Acknowledgements & Questions\nThanks to everyone at NASA-TOPS, Columbia, ISciences, and the TOPS-SCHOOL team.\n\n\n\n\n\n\n\n\n\nSEDAC Workshop on Open Science, Palisades NY"
  },
  {
    "objectID": "presentations/sedac-open-science-brinks-01_09_24.html#lesson-goals",
    "href": "presentations/sedac-open-science-brinks-01_09_24.html#lesson-goals",
    "title": "TOPS-SCHOOL WSIM (GLDAS)",
    "section": "Lesson Goals",
    "text": "Lesson Goals\n\nThe objective of this lesson is to provide content for learning water resource issues through data exploration and analysis.\nWe are introducing 3 datasets for this module\n\nMODIS NRT Flood Data\nNYC Lead Data\nWSIM-GLDAS"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome SCHOOL Module 1: Water",
    "section": "",
    "text": "Welcome to the first module of the TOPSTSCHOOL curriculum!\nThe Science Core Heuristics for Open Science Outcomes in Learning (SCHOOL) is part of the NASA Transform to Open Science (TOPS) Training (TOPST) initiative, designed to generate an inclusive culture of open science. You can learn more about the SCHOOL Project and other modules on the SCHOOL Project home page.\nThe first SCHOOL Module: Water explores how humans impact the water cycle and are affected by the changes they cause. The module consists of three vignettes which cover examples of water use, safety, and anomalies such as droughts and floods. Each vignette uses a unique dataset to walk users through lessons in accessing and analyzing data, and further adapting the code to perform their own analyses including data cleaning, processing to subset to an area of interest, and creating visualizations to share what they have learned with their communities.\nThe SCHOOL Modules do not intend to teach all-encompassing earth science lessons nor provide learners with total coding expertise. Instead, the SCHOOL Project aims to provide users with the skills to adapt the SCHOOL lessons to the users’ own Open Science workflow.\nThe Module 1: Water datasets and vignettes cover:\n\nWSIM-GLDAS: Exploring water anomalies using a historical dataset.\n\nLesson 1: Acquiring and Pre-Processing WSIM-GLDAS\nLesson 2: Advanced Visualizations with WSIM-GLDAS\n\nMODIS Near Real Time flood data: Lessons in data acquisition and analysis of recent water anomalies.\n\nLesson 3: Acquiring and Exploring MODIS NRT Flood Data\n\nLead in New York State Schools: Exploring lead contamination data and US Census data and lessons in data cleaning and visualization, with a discerning eye towards data limitations.\n\nLesson 4: NYC School Water Quality: Exposure to Lead Data\nLesson 5: NYC School Lead Exposure Interactive Explorer\n\nConclusion: Module wrap up and knowledge check. + Lesson 5: Conclusion\n\nThis course was made possible thanks to the work of our NASA Transform to Open Science (TOPS) team, our SCHOOL Open Science team, open science Subject Matter Experts (SMEs), and the SCHOOL Development team!"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#lesson-2",
    "href": "wsim-gldas-acquisition.html#lesson-2",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Lesson 2",
    "text": "Lesson 2\nIn the next lesson we will create more advanced visualizations and extract data of interest.\nLesson 2: WSIM-GLDAS Visualizations and Data Extraction"
  },
  {
    "objectID": "wsim-gldas-vis.html#conlusion",
    "href": "wsim-gldas-vis.html#conlusion",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Conlusion",
    "text": "Conlusion\nThe insights drawn from various data sources, including remote sensing data, contribute to the understanding of water availability. Models like the Global Land Data Assimilation System (GLDAS) utilize satellite and ground-based observations to provide real-time, high-resolution data on land surface states and fluxes, aiding in a more comprehensive understanding of drought and flooding."
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "References\n\nCarroll, M. L., C. M. DiMiceli, J. R. G. Townshend, R. A. Sohlberg, A. I. Elders, S. Devadiga, A. M. Sayer, and R. C. Levy. 2016. “Development of an Operational Land Water Mask for MODIS Collection 6, and Influence on Downstream Data Products.” International Journal of Digital Earth 10 (2): 207–18. https://doi.org/10.1080/17538947.2016.1232756.\n\n\nLand, Atmosphere Near real-time Capability for EO (LANCE). 2024. “About LANCE.” January 11, 2024. https://www.earthdata.nasa.gov/learn/find-data/near-real-time/about-lance.\n\n\nLin, Li, Liping Di, Junmei Tang, Eugene Yu, Chen Zhang, Md. Rahman, Ranjay Shrestha, and Lingjun Kang. 2019. “Improvement and Validation of NASA/MODIS NRT Global Flood Mapping.” Remote Sensing 11 (2): 205. https://doi.org/10.3390/rs11020205.\n\n\nSlayback, D. 2023. “Modis NRT Global Flood Product - Earthdata.” https://www.earthdata.nasa.gov/s3fs-public/2023-01/MCDWD_UserGuide_RevC.pdf.\n\n\nWilson, James. 2024. “NASA API Overview.” November 30, 2024. https://github.com/wilsjame/how-to-nasa?tab=readme-ov-file.\n\n\nZhang, Chen, Zhengwei Yang, Liping Di, Eugene G. Yu, Bei Zhang, Weiguo Han, Li Lin, and Liying Guo. 2022. “Near-Real-Time MODIS-Derived Vegetation Index Data Products and Online Services for CONUS Based on NASA LANCE.” Scientific Data 9 (1). https://doi.org/10.1038/s41597-022-01565-2.\n\nFootnotes\n\n\nPhoto Credit, NASA OESDIS.↩︎\nPhoto Credit, NASA GSFC.↩︎\nValue 2 (Recurring flood) is not populated in the beta release.↩︎"
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#overview",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#overview",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "In this lesson, you will take a closer look at the data from the LANCE MODIS Near Real Time (NRT) Global Flood Product, including learning about what are LANCE and MODIS, and the NRT Flood products available. You will then learn to select, download, and visualize one of the NRT Flood layers."
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#learning-objectives",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#learning-objectives",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "After completing this lesson, you should be able to:\n\nDetermine what NRT raster data is available by navigating the LANCE website.\nRead a tile map and select a raster tile to download based on a point of interest.\nDownload near-real-time raster data using the application programming interfaces (APIs) with the GET HTTP request method (Wilson 2024).\nView the downloaded raster data to quickly preview.\nClassify and place on a map the NRT flood raster data to determine areas with unusual flooding."
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#introduction",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#introduction",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "The MODIS/Aqua+Terra Global Flood Product L3 Near Real Time (NRT) 250m Global Flood Product (MCDWD_L3_NRT) (beta) provides daily maps of flooding globally. The product is provided over 3 compositing periods (1-day, 2-day, and 3-day) to minimize the impact of clouds and more rigorously identify flood water (the best composite will depend on the cloudiness for a particular event) (Lin et al. 2019)"
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#what-are-modis-and-lance",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#what-are-modis-and-lance",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "The Moderate Resolution Imaging Spectroradiometer (MODIS) is a NASA Earth Observing System (EOS) satellite-based sensor system that creates data products including land surface temperatures, land surface reflectance, radiances, clouds, aerosols, water vapor, active fire, snow cover, sea ice measurements, and other factor information. The MODIS Near Real-Time (NRT) data includes the Flood product which is a daily ~250 m resolution product showing flood and surface water detected from the twice-daily overpass of the MODIS optical sensors.\nThe satellite data is readily available shortly after it is acquired by the MODIS instrument on board the Terra and Aqua satellites. This space-based instrument distinguishes 36 spectral bands and groups of wavelengths which helps map the extent of snow and ice caused by winter storms and frigid temperatures. Initially, the water-detecting algorithm is applied to both MODIS observations (Terra and Aqua). Due to cloud and terrain shadows create false positives.\n2\nTo minimize errors, the product is generated with three different compositing periods (1-day, 2-day, and 3-day) to compare results and decide which product has better coverage for the event. Further, they have to differentiate floods from expected surface water through the use of MODIS Land Water Mask (MOD44W), which uses a decision tree classifier trained with MODIS data to produce a global water mask (Carroll et al. 2016).\nMODIS adoption aimed to surpass barriers related to satellite data, including cost, delivery timelines, limited formats, and the need for technical expertise. The transition to GFIMS establishes an operational system at FAO, ensuring continuity in meeting NASA data-user needs (Lin et al. 2019).\n\n\n\nThe Land, Atmosphere Near Real-time Capability for EOS (LANCE) is a NASA initiative that provides near real-time access to satellite data, including MODIS. It allows users to access the latest data within a few hours of satellite overpass, enabling rapid responses to environmental events such as floods. LANCE is particularly valuable for emergency response teams and researchers who require up-to-date information for monitoring and assessing natural disasters (Land 2024).\nLANCE reduces processing time, allowing for timely computation. Users access the data through platforms like Web Map Service (WMS) and Web Coverage Service (WCS), enabling visualization and analysis for informed decision-making. This NRT approach enhances the speed and accessibility of critical information on vegetation conditions (Zhang et al. 2022).\n\n\n\nNASA EARTHDATA\nCRM SEARCH\nThe MODIS/Terra+Aqua Combined MODIS Water Detection (MCDWD) algorithm is tailor-made for detecting water bodies using MODIS data obtained from both the Terra and Aqua satellites. This algorithm employs various bands and spectral information to effectively identify and categorize water bodies. This enhances the accuracy and reliability of the flood product generated (Slayback 2023).\nThe MODIS Near Real-Time (NRT) Flood dataset offers multiple products, each accompanied by corresponding layers. The specific layers depend on the temporal aggregation:\nMCDWD_F1_L3_NRT (1-Day product) This product type is the most basic level and provides binary information about water occurrence. Pixels are classified as either containing water or not, offering a simple way to identify flooded areas.\nMCDWD_F1CS_L3_NRT (1-Day CS): F1CS has a cloud shadow mask applied on the version of the MCDWD_F1_L3_NRT product\nMCDWD_F2_L3_NRT (2-Day): F2 provides additional information by categorizing water occurrences into three categories: no water, low-confidence water, and high-confidence water. This classification allows for a more nuanced understanding of the extent of the flood and its associated confidence levels.\nMCDWD_F3_L3_NRT (3-Day): The F3 product, based on the MCDWD (MODIS/Terra+Aqua Combined MODIS Water Detection) is an algorithm that further refines flood mapping by adding additional spectral information. These results create a more accurate representation of water bodies and flooded areas (Slayback 2023)."
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#reading-the-data",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#reading-the-data",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "For this exercise, we will be using the MCDWD L3 F3 product: LANCE NRT Flood\nFirst, install and load the R packages required for this exercise:\n\npackages_to_check &lt;- c(\"stars\", \"httr\", \"jsonlite\", \"tmap\", \"basemaps\")\n\n# Check and install packages\nfor (package_name in packages_to_check) {\n  if (!package_name %in% rownames(installed.packages())) {\n    install.packages(package_name)\n    cat(paste(\"Package\", package_name, \"installed.\\n\"))\n  } else {\n    cat(paste(\"Package\", package_name, \"is already installed.\\n\"))\n  }\n  library(package_name, character.only = TRUE)\n}\n\n#in case tmap does not install\n#remotes::install_github('r-tmap/tmap')\n\n\n\nBased on availability, edit the year_day variable YYYY-DD. Example: ‘2022-01’\n\n#add the year and date you want to search for (YYYY-DD, 2022-01)\nyear_day &lt;- '2024-023'\n\n\n\n\nMODIS NRT Tile Map\n\nBased on availability, edit the tile_code variable:\n\n#add tile code from the map above (written as h00v00)\ntile_code &lt;- 'h05v05'\n\nThis is the NRT Flood F3 (MCDWD_L3_F3) API URL:\n\n#API_URL &lt;- paste0('https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=')\n\n# if the primary server is down, the secondary server may be available:\nAPI_URL &lt;- paste0('https://nrt4.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=')\n\nWe can combine the API URL above with the year_day provided and print the available datasets:\n\n#pasting together URL and year_day\nurl &lt;- paste0(API_URL, year_day)\nprint(url)\n\n[1] \"https://nrt4.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=2024-023\""
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#loading-the-data",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#loading-the-data",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "Access the NASA Earthdata with the GET function:\n\n# Make the GET request\nresponse &lt;- httr::GET(url)\n\nCheck the response status from the GET function:\n\nresponse\n\nResponse [https://nrt4.modaps.eosdis.nasa.gov/api/v2/content/details?products=MCDWD_L3_F3_NRT&archiveSets=61&temporalRanges=2024-023]\n  Date: 2024-01-29 20:48\n  Status: 200\n  Content-Type: application/json;charset=UTF-8\n  Size: 113 kB\n\n\nOut of the response from the server, we’ll check if the response was a success with if (http_status(response)$category == \"Success\"). If this statement is true, then the content will be assigned to the variable data in JSON format, which is then parsed to a data frame using data_parsed &lt;- jsonlite::fromJSON(data). The data frame contains data_parsed$content, a column with content. We filter the content by tile code using the command content_items &lt;- data_parsed$content[grepl(tile_code, data_parsed$content$name, ignore.case = TRUE), ] and add the results to a data frame.\n\n# Check the response status\nif (httr::http_status(response)$category == \"Success\") {\n  # Parse the response JSON\n  data &lt;- httr::content(response, as = \"text\", encoding = \"UTF-8\")\n  data_parsed &lt;- jsonlite::fromJSON(data)\n  #filter for the tile code\n  content_items &lt;- data_parsed$content[grepl(tile_code, data_parsed$content$name, ignore.case = TRUE), ]\n} else {\n  print(\"Request failed with status code\", httr::http_status(response)$status_code)\n}\n\nprint(content_items)\n\n   archiveSets      cksum    collections               dataDay\n23          61 3182139075 modis-nrt-c6.1 2024-023 = 2024-01-23\n                                                                                         downloadsLink\n23 https://nrt4.modaps.eosdis.nasa.gov/api/v2/content/archives/MCDWD_L3_F3_NRT.A2024023.h05v05.061.tif\n       fileId                           md5sum      mtime\n23 1994021013 061b3cdc621ffad2cf9a24cbe239ab5b 1706065072\n                                      name        products resourceType\n23 MCDWD_L3_F3_NRT.A2024023.h05v05.061.tif MCDWD_L3_F3_NRT         File\n                                                              self   size\n23 /api/v2/content/details/MCDWD_L3_F3_NRT.A2024023.h05v05.061.tif 794917\n\n\nSelect the URL from the ‘downloadsLink’ column in the content_items data frame:\n\ndownload_link &lt;- content_items$downloadsLink\nprint(download_link)\n\n[1] \"https://nrt4.modaps.eosdis.nasa.gov/api/v2/content/archives/MCDWD_L3_F3_NRT.A2024023.h05v05.061.tif\"\n\n\nUse the “read_stars()” function from the “stars” R Library to read the geoTiff raster. The raster is assigned to the “raster_df” variable:\n\nraster_df &lt;- stars::read_stars(download_link)\n\nSet the Coordinate Reference System (CRS) to a new raster “my_raster” to plot it in a map. For example, Web Mercator EPSG:3857. Use the st_transform() function:\n\nraster_df &lt;- sf::st_transform(raster_df, 3857)\n\nNow the raster data should be stored as a variable “my_raster” with the CRS set to Web Mercator EPSG:3857"
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#visualizing-nrt-flood-data",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#visualizing-nrt-flood-data",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "Plot the raster to quickly view it:\n\nplot(raster_df, axes = TRUE)\n\n\n\n\n\n\n\n\n\n\nRefer to the MODIS NRT Global Flood Product User Guide for more information.\nNRT Flood data has 5 classifications:\n\n\n\nCode\nDefinition\n\n\n\n\n0\nNo Water\n\n\n1\nSurface Water\n\n\n2\nRecurring flood3\n\n\n3\nFlood (unusual)\n\n\n255\nInsufficient data\n\n\n\nTo view the data in this classification, we’ll need to create a classified legend; however, the NRT Flood data is stored in decimal numbers (aka floating-point). Create class breaks dividing the data by the following breaks, and corresponding colors and labels:\n\nclass_breaks &lt;- c(-Inf, 0.1, 1.1, 2.1, 3.1)\ncolors &lt;- c( \"gray\", \"blue\", \"yellow\", \"red\")\n\nlabels = c(\"0: No Water\", \"1: Surface Water\", \"2: Recurring flood\", \"3: Flood (unusual)\")\n\nAdd a title for the plot that includes the year, day of year, and tile code:\n\ntitle = paste(\"Near Real-Time Flood F3\", year_day, tile_code)\n\n\n\n\nTo generate a basemap that shows the location of our raster, we must first create a bounding box to match raster_df.\n\nbbox &lt;-  sf::st_bbox(raster_df)\n\nThe basemap_stars() function from the stars library allows us to access Esri imagery layers. We choose “world_imagery” as our background and assign it to the object bm_m.\n\nbm_m &lt;- basemaps::basemap_stars(bbox, map_service = \"esri\", map_type = \"world_imagery\")\n\nLoading basemap 'world_imagery' from map service 'esri'...\n\n\nThe st_rgb function lets us turn the RGB stars item into a single image\n\nbm_m &lt;- stars::st_rgb(bm_m)\n\n\n\n\nGenerate a plot from the tmap library using the tm_shape() function. We will plot the basemap and the raster_df items.\n\n## tmap mode set to \"plot\"\ntmap::tmap_mode(\"plot\")\n\n## tmap mode can also be set to \"view\"\n#tmap_mode(\"view\")\n\n#create an object the plots the basemap and the NRT flood raster\n#with the tmap library, call the tm_shape() function for the basemap\ntm_plot &lt;- tmap::tm_shape(bm_m)+\n  tmap::tm_raster()+\n  #create a new tmap shape for the NRT flood raster with style as \"cat,\" meaning categorical.\n  tmap::tm_shape(raster_df, style=\"cat\")+\n  #add the classification styling to the raster\n  tmap::tm_raster( palette = c(colors),\n  title = title, \n  breaks = class_breaks,\n  labels = labels )+\n  #style the plot\n  tmap::tm_layout(legend.outside = TRUE) +\n  tmap::tm_graticules(lines=FALSE)\n\nView the plot:\n\ntm_plot"
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#in-this-lesson-you-learned",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#in-this-lesson-you-learned",
    "title": "MODIS NRT Global Flood Product",
    "section": "",
    "text": "Congratulations! Now you should be able to:\n\nNavigate the LANCE data website and determine what data is available.\nSelect a tile and date to download NRT data.\nCreate a GET HTTP request to download near-real-time data.\nPlot on a map and classify raster data to determine areas with unusual flooding."
  },
  {
    "objectID": "lance-modis-nrt-global-flood-mcdwd-f3.html#footnotes",
    "href": "lance-modis-nrt-global-flood-mcdwd-f3.html#footnotes",
    "title": "MODIS NRT Global Flood Product",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPhoto Credit, NASA OESDIS.↩︎\nPhoto Credit, NASA GSFC.↩︎\nValue 2 (Recurring flood) is not populated in the beta release.↩︎"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html",
    "href": "exposure_to_lead_in_schools_nys.html",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "",
    "text": "This document helps to analyse school lead datasets collected from 2016,2017,2018 and 2019 and compare it with population characteristic at county level in NYS.\n\n\n\n\nPossible health outcomes of consuming water with lead level above 15pbb and importance of water quality\nRea into R and analyze the data set\nConvert school lead survey dataset to spatial data by using school xy coordinates\nPlot school locations on a map\nObtain population data from US Census Bureau by using census API\nCompare school lead datasets with population by aggregating the dataset into country boudary\nExplore different data classification methods ( equal, quantile, natural breaks, standard deviation)\nCreate your own map"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#objective",
    "href": "exposure_to_lead_in_schools_nys.html#objective",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "",
    "text": "This document helps to analyse school lead datasets collected from 2016,2017,2018 and 2019 and compare it with population characteristic at county level in NYS.\n\n\n\n\nPossible health outcomes of consuming water with lead level above 15pbb and importance of water quality\nRea into R and analyze the data set\nConvert school lead survey dataset to spatial data by using school xy coordinates\nPlot school locations on a map\nObtain population data from US Census Bureau by using census API\nCompare school lead datasets with population by aggregating the dataset into country boudary\nExplore different data classification methods ( equal, quantile, natural breaks, standard deviation)\nCreate your own map"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#background-information",
    "href": "exposure_to_lead_in_schools_nys.html#background-information",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "Background Information",
    "text": "Background Information\nAccess to clean and safe drinking water is significant to ensure public health. Drinking water contaminants may have both short-term and long-term negative health impacts. One such contaminant that can have detrimental effects is lead, which is particularly harmful to a child’s development. Children’s central nervous systems and cognitive function have been linked to harm from lead exposure, even at low levels . It is therefore essential to supply lead free drinking water in schools and homes.\nLead concentrations in drinking water should not exceed 10 ppb, according to guidelines issued by the World Health Organization, and 15 ppb is the action level set by the US EPA . These guidelines demonstrate how important it is to reduce lead exposure and contamination from drinking water on a global scale. Lead exposure has no safe threshold. Safety depends on making sure that lead levels in water are below legal thresholds, and ideally as close to zero as feasible since it can have serious negative health impacts, especially in children\nThe main source of lead in drinking water is the corrosion of lead-containing plumbing materials. The EPA considers lead levels over 15 ppb to be dangerous. Lead poisoning must be prevented at all costs, particularly in schools where young students’ developing brains are vulnerable. Developing effective preventive and remedial strategies requires an understanding of the factors that contribute to lead contamination. It is significant to understand that the distribution of lead contamination often coincides with socioeconomic issues . Lead exposure often has a disproportionate impact on communities with lower incomes and limited access to resources . Older plumbing systems with lead pipes and solder may leak lead into drinking water, particularly in regions with acidic water . Furthermore, runoff from contaminated soil and industrial discharges can also introduce lead into water systems. Low income communities’ residential areas often lack access to safe drinking water due to inadequate infrastructure or reliance on private wells that may be contaminated with lead. Studies also show that most of these low income and marginalized groups reside in the areas which are more likely to be located near industrial facilities and other sources which are exposed to lead pollution .\n\nLEAD IN NEW YORK SCHOOLS\nNew York State (NYS) Lead Testing in School Drinking Water dataset analysis reveals that as of 2022, 1,864 schools had lead outlets testing higher than 15 ppb . While 527 schools finished their remediation, 1,851 schools reported taking remedial action. There are now 12 schools with outlets exceeding 15 ppb in operation, indicating possible continuous exposure. There are gaps evident with following up and documenting the corrective measures. To understand and mitigate the lead hazards, more transparency is needed around the schools which are at high exposure to the lead and improved repeated testing protocols could be in place. Guidelines, rules, and resources pertaining to lead testing and remediation in schools are provided by the New York State Department of Health . However, it seems that there is currently a lack of financial and technical support to schools to handle lead hazards, particularly in underprivileged communities.\n\n\nFLINT MICHIGAN LEAD EXPOSURE\nThousands of people were exposed to dangerously high lead levels in their drinking water when the Flint water crisis broke out in 2014. According to a study conducted by Virginia tech researchers through their resident organized sampling to testing data from 252 homes revealed that Lead levels in the city had increased with over 17% of samples testing higher than the federal “action level” of 15 parts per billion (ppb), which calls for the need for corrective action. More than 40% had lead readings higher than 5 parts per billion, which the researchers deemed indicative of a “very serious” issue .\nThe article by NY times describes how, in 2019 , Thirty Flint school buildings’ drinking water samples had excessive lead levels. This demonstrates how the problems remained and continued to affect children’s health and development years after the Flint water crisis started. Schools have an obligation to supply their pupils with clean drinking water. Rather than waiting for concerns to arise, schools can detect contamination issues early and take corrective action by implementing a lead testing program. Better learning outcomes are made possible by shielding schoolkids from lead exposure.\nTo mitigate the lead hazards, Initial step is to understand that it’s essential to regularly test and monitor the drinking water in households and schools to identify lead contamination. When elevated lead levels are found, the first course of action for mitigation is to quickly close down the source and offer alternatives for drinking water. Replacing plumbing and lead service lines is necessary for longer-term mitigation in order to eliminate the primary source of contamination. Applying corrosion inhibitors is an additional strategy to stop infrastructure from leaking lead. Maintaining transparency and exchanging information with communities regarding the outcomes of lead testing and mitigation strategies is essential. However, significant infrastructural changes are required to totally eliminate lead dangers. To assist schools and underprivileged communities in completing thorough lead abatement and ensuring safe and accessible drinking water for all. In line with above actions and past Flint water crisis, the state of Michigan approved\n$97 million in funding for service line replacement . However, still substantial investments and coordinated efforts are needed to fully remediate risks, especially in disadvantaged communities .\nIn 2021, the Biden-Harris administration announced an ambitious Lead Pipe and Paint Action Plan. This comprehensive 15 billion dollar effort intends to promptly replace all lead service lines and pipes that are contaminating drinking water systems across the country. The plan has a provision of providing a lead remediation grant of $9 billion to disadvantaged communities through the Water Infrastructure Improvements for the Nation Act (WIIN) program, including for schools and childcare centers at EPA .\n\n\nENSURING SAFE DRINKING WATER\nThe lead contamination issues evident in Flint and New York schools highlight the need to balance the tradeoffs between quickly addressing risks in the short term by improving monitoring and transparency around water quality issues, and managing the costs of major infrastructure changes required in the long term to prevent such crises and exposures - for example, replacing lead service lines and school plumbing. Community collaboration, precise surveillance databases, and adaptable adaptation strategies will be critical to ensuring that everyone has access to safe drinking water.\nAvailability of safe drinking water is the basic human right, however from above cases it shows the alarming need to consider this risk from the lead contamination yet ignored by the state. From New York to Flint, Michigan, we witness alarming examples that necessitate immediate action backed by transparent and accessible data. Moreover an informed public through the learnings and accessing the data, can play a crucial role in building leadership roles to fulfill their responsibilities around providing healthy, lead free infrastructures in schools. Thus , it is significant to develop the curriculum which focuses on water quality issues globally and locally for students and school communities.\n\n\nRead data\n\nThe section below reads NYS school lead testing result from 2016 to 2019.The datasets is hosted on github reposotory. We are going to read the dataset by uisng dataset url\n\n\n# dataset url on github repository\ndata_url&lt;-\"https://raw.githubusercontent.com/renastechschool/Python_tutorials/main/Lead_Testing_in_School_Drinking_Water_Sampling_and_Results_Compliance_Year_2016_formated.csv?token=GHSAT0AAAAAACNH7S3BJGTQXNGH4UPQCJI6ZNQB3VA\"\n# read dataset.Input data wrapped by url mothod.This allows to read data from a url\nschool_lead_df&lt;-read_csv(url(data_url))\n\n\n\nPrepairing the lead dataset for the analysis\n\nAll datasets requires some pre-cleaning and formatting. In the section below, we format fields names. R do not like fields names with space so we need to convert space to underscore “_”. Also We need to extract year from date field for following part of the this work.\n\n\n#  There are empty space in the field name and R do not like them\n# line below replace empty space with _\nnames(school_lead_df) &lt;- names(school_lead_df) %&gt;% stringr::str_replace_all(\"\\\\s\",\"_\")\n\n\n# extract year from date field. we are using Date_Results_Updated for the date\nschool_lead_df&lt;-school_lead_df %&gt;%  mutate(year=format(as.Date(Date_Results_Updated, format=\"%d/%m/%Y\"),\"%Y\"))\n\n# data reports lead level by outlets if a outlet lead level above or under 15ppb\n# the line below categorized he schools if they have any outlet above or under 15ppb\nschool_lead_df&lt;-school_lead_df %&gt;%  mutate(lead_summary_by_school=case_when(\n                                          Number_of_Outlets_above_15_ppb ==0~ \"has lead &lt; 15ppb\",\n                                          Number_of_Outlets_above_15_ppb &gt;0~ \"has lead &gt;15ppb\",\n                                          TRUE ~ \"no data\"))\n\n\n\nGet fimiliar with the dataset\n\nGetting familiar with the dataset is the first step of an analysis. The section below allows to get to know the datasets attributes in detail. It allaws to query data by geocraphic region (county) and different attributes ( fields)\n\n\n#| panel: fill\nfluidPage(\n      fluidRow(style = \"padding-bottom: 30px;background-color:#f1f2f3;\",\n        select_county,select_fields4),\n      fluidRow(column(12, DT::dataTableOutput(\"table\"))))\n\n\n#| context: server\noutput$table&lt;- DT::renderDataTable({\nif (input$county==\"All Counties\")\n    {school_lead_df %&gt;% dplyr::select(input$fields) }\n\n  else(school_lead_df %&gt;% filter(County==input$county)%&gt;% dplyr::select(input$fields))\n})"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#conversion-from-tabular-data-to-geo-spatial-data",
    "href": "exposure_to_lead_in_schools_nys.html#conversion-from-tabular-data-to-geo-spatial-data",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "Conversion from tabular data to geo-spatial data",
    "text": "Conversion from tabular data to geo-spatial data\n\nA dataset needs to have a geometry attribute to plot the data on a map or do different spatial analysis.The dataset have xy coordinates of schools. XY coordinates allows us to convert the tabular dataset to spatial dataset. The section does the this conversion. There is another point needs to be taken into account while the conversion is done. We need to know projection of xy coordinates. XY coordinates can be in different projections systems. Projection information mostly is stored in the metadata but unfortunately there is no any metadata attached to the dataset.However the most common projection is the geographic coordinate system. WGS84 projection is used to make the dataset to spatial dataset. There is another problem needs to solved priority to the conversion. XY coordinates are not properly formatted. This is an example 231-02 67 AVENUE Queens, NY 11364(40.74779141700003, -73.74551716499997). We need to extract (40.74779141700003, -73.74551716499997) part and store each side of comma two separate fields. The first number refers to y (latitude) coordinate, second number refers to x (longitude) coordinate.\n\n\n\n# In the datasets xy coordinates of schools  are combined with school address and recorded under\n# location field as 231-02 67 AVENUEQueens, NY 11364(40.74779141700003, -73.74551716499997)\n# (40.74779141700003, -73.74551716499997) needs to be extracted and sparated by \",\" and \n# saved undr different fields names\n# line below extract xy coordinates and save under \"lat\",\"long\" fields\nschool_lead_df&lt;-school_lead_df %&gt;% mutate(location_temp=str_extract(Location,\"(?&lt;=\\\\().*(?=\\\\))\")) %&gt;% \n  separate(location_temp,c(\"lat\",\"long\"),sep=\",\")\n\n# line below create geometry attributes by using lat long fields and \n# geographic coordinate system\n# this step allow us to map the school locations and do some geospatial anaylysis\nschool_locations&lt;-school_lead_df %&gt;%  filter(!is.na(lat)) %&gt;% \n  # convert the dataset to spatial dataset by using WGS84 projection\n  st_as_sf(coords = c(\"long\", \"lat\"),crs = \"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\") \n\n\nMapping the dataset\n\nThe section below maps the school location in New York State\n\n\n#|panel: fill\nfluidPage(\n      fluidRow(style = \"padding-bottom: 30px;background-color:#f1f2f3;\",\n               select_county),\n      fluidRow(column(12,leafletOutput(\"map\"))))\n\n\n\nschool_loc&lt;-reactive({school_locations %&gt;% filter(County==input$county)})\n\noutput$map&lt;-renderLeaflet({\n\n  \n#  if (input$county==\"All Counties\"){school_loc &lt;-school_locations\n#    tmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n#   tm_shape(school_loc, name=\"school locations\") +\n#   tm_dots(id=\"\",col=\"County\",palette=\"magma\",\n#         popup.vars=c(\"School name: \"=\"School\" ),\n#         legend.show = FALSE)\n# tmap_leaflet(tmap)\n#  }\n#   \n#   else{school_loc &lt;-school_locations %&gt;% filter(County==input$county)\n  \n  tmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n  tm_shape(school_loc(), name=\"school locations\") +\n  tm_dots(id=\"\",col=\"County\",palette=\"magma\",\n        popup.vars=c(\"School name: \"=\"School\" ),\n        legend.show = FALSE)\ntmap_leaflet(tmap)\n\n\n})"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#abtain-population-data-from-us-census-bureau",
    "href": "exposure_to_lead_in_schools_nys.html#abtain-population-data-from-us-census-bureau",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "Abtain population data from US Census Bureau",
    "text": "Abtain population data from US Census Bureau\n\nThe section below pulls population from US Census Bureau by using census api API.\n\n\n#|panel: fill\n\nfluidPage(\n      fluidRow(style = \"padding-bottom: 20px;background-color:#f1f2f3;\",\n               select_state,select_fields1, select_fields2, select_classification_method),\n\n      fluidRow(column(6, plotOutput(\"plot1\")),\n                column(6, plotOutput(\"plot2\"))),\n      fluidRow(column(6, leafletOutput(\"map1\")),\n                column(6,leafletOutput(\"map2\"))))\n\n\n# get total population from census 2020\ncounty_census&lt;-reactive({\n  req(input$state)\n  get_census_data(input$state) })\n\n\noutput$plot1&lt;-renderPlot({\n\n  county_census()%&gt;%st_drop_geometry() %&gt;%\n    dplyr::select(contains(\"total\")) %&gt;% gather(key,value) %&gt;%\n    group_by(key) %&gt;% summarise(Count=sum(value)) %&gt;%\n    filter(key!=\"total_pop\") %&gt;%\n    mutate(percent = prop.table(Count),  prc=paste0( \"%\",round(percent*100, 1),\" \\n(\", comma(Count/1000),\"K)\")) %&gt;%\n     ggplot(aes(x=key,y=Count,fill=key))+\n    geom_bar(stat=\"identity\")+\n    geom_text(aes(label = prc),size=5, hjust=0.7,\n    position=position_stack(0.9))+guides(fill=FALSE)+\n     labs(x=\"\",y=\" \", fill=\"\", title = \"Total Population by Race\")+\n    coord_flip()+theme\n})\n\noutput$plot2&lt;-renderPlot({\n\n    county_census() %&gt;%st_drop_geometry() %&gt;%\n    dplyr::select(\"white_5_17\",\"black_5_17\",\"hispanic_5_17\",\"asian_5_17\") %&gt;%\n    gather(key,value) %&gt;%\n    group_by(key) %&gt;% summarise(Count=sum(value)) %&gt;%\n    mutate(percent = prop.table(Count),  prc=paste0( \"%\",round(percent*100, 1),\" \\n(\", comma(Count/1000),\"K)\")) %&gt;%\n     ggplot(aes(x=key,y=Count,fill=key))+\n    geom_bar(stat=\"identity\")+\n    geom_text(aes(label = prc),size=5, hjust=0.7,\n    position=position_stack(0.9))+guides(fill=FALSE)+\n     labs(x=\"\",y=\" \", fill=\"\", title = \"Total Populaiton age 5-17 by Race\")+\n    coord_flip()+theme\n})\n\n\noutput$map1&lt;-renderLeaflet({\n\ntmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n  tmap::tm_shape(county_census(), name=\"NYS counties\") +\n  tm_polygons(col=input$field1,style=input$classification, palette=\"RdYlGn\")\ntmap_leaflet(tmap)\n\n})\n\noutput$map2&lt;-renderLeaflet({\n\ntmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n  tmap::tm_shape(county_census(), name=\"NYS counties\") +\n  tm_polygons(col=input$field2,style=input$classification, n=6,palette=\"RdYlGn\")\ntmap_leaflet(tmap)\n\n})"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#explore-your-data-spatially",
    "href": "exposure_to_lead_in_schools_nys.html#explore-your-data-spatially",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "Explore your data spatially",
    "text": "Explore your data spatially\n\n\n\nfluidPage(\n      fluidRow(style = \"padding-bottom: 20px;background-color:#f1f2f3;\",\n              select_state,select_county),\n\n      fluidRow(column(5,\"\", plotOutput(\"plot\")),\n                column(7,\"\", leafletOutput(\"map\"))))\n\n\n\n\ncounties_bry &lt;- reactive({req(input$state)\n                              get_census_data(input$state) })\n\nschool_loc &lt;- reactive({school_locations %&gt;%filter(County==input$county)})\n\n\noutput$plot&lt;-renderPlot({\n  if (input$county==\"All Counties\"){school_lead_df_&lt;-school_lead_df}\n  else{school_lead_df_&lt;-school_lead_df %&gt;% filter(County==input$county)}\n  school_lead_df_ %&gt;%\n  group_by(lead_summary_by_school) %&gt;% summarize(Count=n()) %&gt;%\n    mutate(percent = prop.table(Count),  prc=paste0( \"   %\",round(percent*100, 1),\" (\", comma(Count),\")\")) %&gt;%\n  ggplot(aes(x=lead_summary_by_school,\n                      y=Count,fill=lead_summary_by_school))+\n    geom_bar(stat=\"identity\")+\n  geom_text(aes(label = prc),size=5,\n    position=position_stack(0.9))+guides(fill=FALSE)+\n    scale_fill_manual(values=c(\"green3\",\"red\",\"grey\"))+\n     labs(x=\"\",y=\"Count of School\", fill=\"\", title = \"Count of schools based on lead status\",\n         caption=\"has lead &lt; 15ppb: None of the outlets have lead over 15ppb\\nhas lead &gt;15ppb: At least a outlet has lead over 15ppb\")+theme\n})\n\n\noutput$map&lt;-renderLeaflet({\ntmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n  tmap::tm_shape(counties_bry() , name=\"NYS counties\") +tm_polygons(\"black\",alpha=0,popup.vars=c(\"County Name :  \"=\"county\"))+\n  tm_shape(counties_bry() ,name=\"NYS counties \") +  tm_borders(\"black\", lwd = 2) +\n  tm_shape(school_loc(), name=\"School locations\") +\ntm_dots(id=\"something\",col=\"lead_summary_by_school\",palette=c(\"has lead &lt; 15ppb\"=\"green\",\"has lead &lt; 15ppb\"=\"red\"),\n        popup.vars=c(\"School: \"=\"School\" ),\n        legend.show = FALSE)\ntmap_leaflet(tmap)\n\n})"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#aggregate-school-locations-in-county-boundary-and-compaire-with-county-populaiton",
    "href": "exposure_to_lead_in_schools_nys.html#aggregate-school-locations-in-county-boundary-and-compaire-with-county-populaiton",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "Aggregate school locations in county boundary and compaire with county populaiton",
    "text": "Aggregate school locations in county boundary and compaire with county populaiton\n\nIn the section below, we are aggregating points into county boundary.\n\n\n\n\n fluidPage(\n\n      fluidRow(style = \"padding-bottom: 20px;background-color:#f1f2f3;\",\n\n               select_state,select_fields1,select_fields3, select_classification_method),\n\n      fluidRow(column(6,\"\", leafletOutput(\"map1\")),\n\n               column(6,\"\", leafletOutput(\"map2\"))))\n\n\n\n\n# get total population from census 2020\n\ncounty_bry&lt;-reactive({\n  req(input$state)\n\nget_census_data(input$state)})\n\noutput$map1&lt;-renderLeaflet({\n\n county_bry&lt;- st_transform(county_bry(), crs(school_locations))\n\n  school_locations_join&lt;-st_join(school_locations,county_bry,join = st_intersects) %&gt;%\n\n  group_by(GEOID,county) %&gt;% summarise(school_count=n(),\n\n                               outlets_under_15_ppb=sum(Number_of_Outlets_under_15_ppb, na.rm =TRUE),\n\n                               outlets_above_15_ppb=sum(Number_of_Outlets_above_15_ppb, na.rm=TRUE)) %&gt;%\n\n  dplyr::select(GEOID,county,school_count,outlets_under_15_ppb,outlets_above_15_ppb) %&gt;% st_drop_geometry()\n\n  county_with_school&lt;-county_bry%&gt;% left_join(school_locations_join, by=\"GEOID\")\n\ntmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n\n  tmap::tm_shape(county_with_school, name=\"county boundaries\") +\n\n  tm_polygons(col=input$field1,style=input$classification, n=6,palette=\"YlOrRd\")\n\ntmap_leaflet(tmap)\n\n})\n\noutput$map2&lt;-renderLeaflet({\n\n county_bry&lt;- st_transform(county_bry(), crs(school_locations))\n\n  school_locations_join&lt;-st_join(school_locations,county_bry,join = st_intersects) %&gt;%\n\n  group_by(GEOID,county) %&gt;% summarise(school_count=n(),\n\n                               outlets_under_15_ppb=sum(Number_of_Outlets_under_15_ppb, na.rm =TRUE),\n\n                               outlets_above_15_ppb=sum(Number_of_Outlets_above_15_ppb, na.rm=TRUE)) %&gt;%\n\n  dplyr::select(GEOID,county,school_count,outlets_under_15_ppb,outlets_above_15_ppb) %&gt;% st_drop_geometry()\n\n  county_with_school&lt;-county_bry%&gt;% left_join(school_locations_join, by=\"GEOID\")\n\ntmap&lt;-tm_basemap(leaflet::providers$Esri.WorldImagery)+\n\n  tmap::tm_shape(county_with_school, name=\"county boundaries\") +\n\n  tm_polygons(col=input$field3,style=input$classification, n=6,palette=\"YlOrRd\")\n\ntmap_leaflet(tmap)\n\n})"
  },
  {
    "objectID": "exposure_to_lead_in_schools_nys.html#references",
    "href": "exposure_to_lead_in_schools_nys.html#references",
    "title": "NYC School Water Quality: Exposure to Lead",
    "section": "References",
    "text": "References\n\n1 Lanphear BP, Hornung R, Khoury J, Yolton K, Baghurst P, Bellinger DC, et al. Low-level environmental lead exposure and children’s intellectual function: an international pooled analysis. Environ Health Perspect [Internet]. 2005 Jul [cited 2023 Dec 7];113(7):894–9. Available from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1257652/\n2 Guidelines for drinking-water quality, 4th edition, incorporating the 1st addendum [Internet]. [cited 2023 Dec 7]. Available from: https://www.who.int/publications-detail-redirect/9789241549950\n3 Lanphear BP, Hornung R, Khoury J, Yolton K, Baghurst P, Bellinger DC, et al. Low-level environmental lead exposure and children’s intellectual function: an international pooled analysis. Environ Health Perspect [Internet]. 2005 Jul [cited 2023 Dec 7];113(7):894–9. Available from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1257652/\n4 Pelc W, Pawlas N, Dobrakowski M, Kasperczyk S. Environmental and socioeconomic factors contributing to elevated blood lead levels in children from an industrial area of Upper Silesia. Enviro Toxic and Chemistry [Internet]. 2016 Oct [cited 2023 Dec 25];35(10):2597–603. Available from: https://setac.onlinelibrary.wiley.com/doi/10.1002/etc.3429\n5Schaider LA, Swetschinski L, Campbell C, Rudel RA. Environmental justice and drinking water quality: are there socioeconomic disparities in nitrate levels in U.S. drinking water? Environmental Health [Internet]. 2019 Jan 17 [cited 2023 Dec 25];18(1):3. Available from: https://doi.org/10.1186/s12940-018-0442-6\n6 US EPA O. Basic information about lead in drinking water [Internet]. 2016 [cited 2023 Dec 25]. Available from: https://www.epa.gov/ground-water-and-drinking-water/basic-information-about-lead-drinking-water\n7 PSCI [Internet]. 2020 [cited 2023 Dec 25]. Racial disparities and climate change. Available from: https://psci.princeton.edu/tips/2020/8/15/racial-disparities-and-climate-change\n8 New York State Department of Health | Health Data NY [Internet]. [cited 2023 Dec 7]. Lead testing in school drinking water sampling and results compliance year 2016 | state of new york. Available from: https://health.data.ny.gov/Health/Lead-Testing-in-School-Drinking-Water-Sampling-and/rkyy-fsv9\n9 Lead testing of school drinking water [Internet]. [cited 2023 Dec 7]. Available from: https://www.health.ny.gov/environmental/water/drinking/lead/lead_testing_of_school_drinking_water.htm\n10 Flint water crisis: everything you need to know [Internet]. 2018 [cited 2023 Dec 21]. Available from: https://www.nrdc.org/stories/flint-water-crisis-everything-you-need-know\n11 Green EL. Flint’s children suffer in class after years of drinking the lead-poisoned water. The New York Times [Internet]. 2019 Nov 6 [cited 2023 Dec 21]; Available from: https://www.nytimes.com/2019/11/06/us/politics/flint-michigan-schools.html\n12 Flint residents still fighting to replace lead pipes, get torn yards fixed | Bridge Michigan [Internet]. [cited 2023 Dec 25]. Available from: https://www.bridgemi.com/michigan-environment-watch/flint-residents-still-fighting-replace-lead-pipes-get-torn-yards-fixed\n18 How the Flint water crisis has impacted US lead-pipe removal efforts [Internet]. [cited 2023 Dec 25]. Available from: https://www.asce.org/publications-and-news/civil-engineering-source/civil-engineering-magazine/article/2021/08/how-the-flint-water-crisis-has-impacted-us-lead-pipe-removal-efforts\n14 House TW. The White House. 2021 [cited 2023 Dec 25]. Fact sheet: the biden-harris lead pipe and paint action plan. Available from: https://www.whitehouse.gov/briefing-room/statements-releases/2021/12/16/fact-sheet-the-biden-harris-lead-pipe-and-paint-action-plan/"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#overview",
    "href": "wsim-gldas-acquisition.html#overview",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Overview",
    "text": "Overview\nIn this lesson, you will use…"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#learning-objectives",
    "href": "wsim-gldas-acquisition.html#learning-objectives",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this lesson, you should be able to: - Determine what…"
  },
  {
    "objectID": "wsim-gldas-acquisition.html#in-this-lesson-you-learned",
    "href": "wsim-gldas-acquisition.html#in-this-lesson-you-learned",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "In this Lesson, You Learned…",
    "text": "In this Lesson, You Learned…\nCongratulations! Now you should be able to:\n\nNavigate the…"
  }
]